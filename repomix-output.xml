This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
MoveInsight/
  Assets.xcassets/
    AccentColor.colorset/
      Contents.json
    AppIcon.appiconset/
      Contents.json
    player_shuttle_distance.imageset/
      Contents.json
    velocity_profile_chart.imageset/
      Contents.json
    Contents.json
  DepthAnythingV2SmallF16.mlpackage/
    Manifest.json
  en.lproj/
    Localizable.strings
  Preview Content/
    Preview Assets.xcassets/
      Contents.json
  zh-Hans.lproj/
    Localizable.strings
  BodyPoseTypes.swift
  ColorManager.swift
  CombinedVideo3DView.swift
  ContentView.swift
  CustomTabBar.swift
  DepthEstimationService.swift
  Extensions.swift
  HomeView.swift
  Info.plist
  ModelVideoLoader.swift
  MoveInsightApp.swift
  Pose3DProcessor.swift
  SceneView3D.swift
  TechniqueAnalysisService.swift
  TechniqueComparisonView.swift
  TechniqueDetailView.swift
  TechniquesListView.swift
  TechniqueVideoUploadView.swift
  UIComponents.swift
  UploadTabView.swift
  VideoPlayerRepresentable.swift
  VideoPlayerViewModel.swift
  VideoTransferUtils.swift
MoveInsight.xcodeproj/
  project.xcworkspace/
    contents.xcworkspacedata
  xcuserdata/
    charlie.xcuserdatad/
      xcschemes/
        xcschememanagement.plist
  project.pbxproj
MoveInsightServer/
  analysis_server.py
  overhead_diagnose.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="MoveInsight/Info.plist">
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
    <key>NSAppTransportSecurity</key>
    <dict>
        <key>NSExceptionDomains</key>
        <dict>
            <key>115.188.74.78</key>
            <dict>
                <key>NSIncludesSubdomains</key>
                <true/>
                <key>NSExceptionAllowsInsecureHTTPLoads</key>
                <true/>
                <key>NSExceptionRequiresForwardSecrecy</key>
                <true/>
                <key>NSExceptionMinimumTLSVersion</key>
                <string>TLSv1.2</string>
                <key>NSThirdPartyExceptionAllowsInsecureHTTPLoads</key>
                <false/>
                <key>NSThirdPartyExceptionRequiresForwardSecrecy</key>
                <true/>
                <key>NSThirdPartyExceptionMinimumTLSVersion</key>
                <string>TLSv1.2</string>
                <key>NSRequiresCertificateTransparency</key>
                <false/>
            </dict>
        </dict>
    </dict>
</dict>
</plist>
</file>

<file path="MoveInsight/TechniqueAnalysisService.swift">
import Foundation
import Vision
import Combine

class TechniqueAnalysisService {
    private let serverURL = URL(string: "http://115.188.74.78:8000")!
    
    struct JointData: Codable {
        let x: Float
        let y: Float
        let confidence: Float
    }
    
    struct FrameJointsData: Codable {
        let joints: [String: [JointData]]
        let dominantSide: String
        
        enum CodingKeys: String, CodingKey {
            case joints
            case dominantSide = "dominant_side"
        }
    }
    
    func compareTechniques(
        userViewModel: VideoPlayerViewModel,
        modelViewModel: VideoPlayerViewModel,
        dominantSide: String = "Right"
    ) -> AnyPublisher<ComparisonResult, Error> {
        // Use getAllPoses to get accumulated poses over time
        let userJoints = extractJointsForServer(from: userViewModel.getAllPoses())
        let modelJoints = extractJointsForServer(from: modelViewModel.getAllPoses())
        
        // Debug info
        print("Sending analysis with \(userViewModel.getAllPoses().count) user frames and \(modelViewModel.getAllPoses().count) model frames")
        if let firstJoint = userJoints.values.first {
            print("First joint has \(firstJoint.count) frames of data")
        }
        
        let userFrameJoints = FrameJointsData(joints: userJoints, dominantSide: dominantSide)
        let modelFrameJoints = FrameJointsData(joints: modelJoints, dominantSide: dominantSide)
        
        let comparisonData = ["user": userFrameJoints, "reference": modelFrameJoints]
        
        return sendRequest(to: "/analyze/comparison", body: comparisonData)
    }
    
    private func extractJointsForServer(from poses: [[VNHumanBodyPoseObservation.JointName: CGPoint]]) -> [String: [JointData]] {
        var result: [String: [JointData]] = [:]
        
        // Log the number of frames we're processing
        print("Processing \(poses.count) frames for analysis")
        
        // Get all unique joint names that appear across all frames
        var allJointNames = Set<String>()
        
        // Map Vision API joint names to Python expected names
        let jointNameMapping: [VNHumanBodyPoseObservation.JointName: String] = [
            .nose: "Nose",
            .leftShoulder: "LeftShoulder",
            .rightShoulder: "RightShoulder",
            .leftElbow: "LeftElbow",
            .rightElbow: "RightElbow",
            .leftWrist: "LeftWrist",
            .rightWrist: "RightWrist",
            .leftHip: "LeftHip",
            .rightHip: "RightHip",
            .leftKnee: "LeftKnee",
            .rightKnee: "RightKnee",
            .leftAnkle: "LeftAnkle",
            .rightAnkle: "RightAnkle"
        ]
        
        // Add special mappings for heel and toe which might not directly map to Vision API
        let specialMappings: [VNHumanBodyPoseObservation.JointName: [String]] = [
            .leftAnkle: ["LeftHeel", "LeftToe"],
            .rightAnkle: ["RightHeel", "RightToe"]
        ]
        
        // Initialize arrays for each joint type
        for joint in jointNameMapping.values {
            result[joint] = []
            allJointNames.insert(joint)
        }
        
        // Add heel and toe (special cases)
        for specialJoints in specialMappings.values {
            for joint in specialJoints {
                result[joint] = []
                allJointNames.insert(joint)
            }
        }
        
        // CRITICAL: This is the key fix - Go through EACH FRAME'S poses and extract joint data
        for frameIndex in 0..<poses.count {
            let pose = poses[frameIndex]
            
            // Add regular joints
            for (visionJoint, serverJoint) in jointNameMapping {
                if let point = pose[visionJoint] {
                    result[serverJoint]?.append(JointData(x: Float(point.x), y: Float(point.y), confidence: 1.0))
                } else {
                    // If joint missing in this frame, use placeholder
                    result[serverJoint]?.append(JointData(x: 0, y: 0, confidence: 0))
                }
            }
            
            // Handle special cases (heel and toe)
            for (ankleJoint, specialJoints) in specialMappings {
                if let anklePoint = pose[ankleJoint] {
                    // For heel, offset backward from ankle
                    let heel = CGPoint(x: anklePoint.x, y: anklePoint.y + 0.03)
                    result[specialJoints[0]]?.append(JointData(x: Float(heel.x), y: Float(heel.y), confidence: 0.8))
                    
                    // For toe, offset forward from ankle
                    let toe = CGPoint(x: anklePoint.x, y: anklePoint.y - 0.05)
                    result[specialJoints[1]]?.append(JointData(x: Float(toe.x), y: Float(toe.y), confidence: 0.8))
                } else {
                    // If ankle not found, add placeholders
                    for joint in specialJoints {
                        result[joint]?.append(JointData(x: 0, y: 0, confidence: 0))
                    }
                }
            }
        }
        
        // Debug logging
        for (joint, frames) in result {
            print("Joint \(joint): \(frames.count) frames")
        }
        
        // Ensure there's enough data for analysis - minimum 10 frames
        if let firstJoint = result.values.first, firstJoint.count < 10 {
            print("WARNING: Not enough frames for analysis. Found only \(firstJoint.count) frames, minimum 10 recommended")
        }
        
        // Filter out empty arrays
        return result.filter { !$0.value.isEmpty }
    }
    
    private func sendRequest<Input: Encodable, Output: Decodable>(to endpoint: String, body: Input) -> AnyPublisher<Output, Error> {
        let url = serverURL.appendingPathComponent(endpoint)
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.addValue("application/json", forHTTPHeaderField: "Content-Type")
        
        do {
            let encoder = JSONEncoder()
            request.httpBody = try encoder.encode(body)
        } catch {
            return Fail(error: error).eraseToAnyPublisher()
        }
        
        return URLSession.shared.dataTaskPublisher(for: request)
            .map(\.data)
            .decode(type: Output.self, decoder: JSONDecoder())
            .receive(on: DispatchQueue.main)
            .eraseToAnyPublisher()
    }
}
</file>

<file path="MoveInsightServer/analysis_server.py">
# analysis_server.py
from fastapi import FastAPI, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, List, Optional
import numpy as np
import logging
import time
import traceback

# Import the evaluation functions from overhead_diagnose.py
from overhead_diagnose import evaluate_swing_rules, align_keypoints_with_interpolation

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("analysis_server")

app = FastAPI()

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Allows all origins
    allow_credentials=True,
    allow_methods=["*"],  # Allows all methods
    allow_headers=["*"],  # Allows all headers
)

# Add middleware to log request timing
@app.middleware("http")
async def log_requests(request: Request, call_next):
    start_time = time.time()
    
    # Get client IP and request details
    client_host = request.client.host if request.client else "unknown"
    logger.info(f"Request started: {request.method} {request.url.path} - Client: {client_host}")
    
    # Process the request
    try:
        response = await call_next(request)
        process_time = time.time() - start_time
        logger.info(f"Request completed: {request.method} {request.url.path} - {response.status_code} in {process_time:.2f}s")
        return response
    except Exception as e:
        logger.error(f"Request failed: {request.method} {request.url.path}")
        logger.error(f"Error: {str(e)}")
        logger.error(traceback.format_exc())
        raise

# Helper function to convert NumPy types to Python native types for JSON serialization
def convert_numpy_types(obj):
    if isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, np.number):
        return obj.item()
    elif isinstance(obj, np.bool_):
        return bool(obj)
    else:
        return obj

# ------------------------- FASTAPI SERVER CODE -------------------------

class JointData(BaseModel):
    x: float
    y: float
    confidence: Optional[float] = 1.0

class FrameJoints(BaseModel):
    joints: Dict[str, List[JointData]]
    dominant_side: str = "Right"

@app.post("/analyze/technique")
async def analyze_technique(data: FrameJoints):
    try:
        logger.info(f"Received technique analysis request with {len(data.joints)} joints")
        # Convert to the format expected by evaluate_swing_rules
        keypoints = {}
        
        # Check if we have enough joints to proceed
        required_joints = [
            f"{data.dominant_side}Shoulder", f"{data.dominant_side}Elbow", 
            f"{data.dominant_side}Wrist", f"{data.dominant_side}Hip",
            'RightHeel', 'RightToe', 'LeftHeel', 'LeftToe'
        ]
        non_dominant = "Left" if data.dominant_side == "Right" else "Right"
        required_joints.extend([f"{non_dominant}Shoulder", f"{non_dominant}Elbow", f"{non_dominant}Hip"])
        
        missing_joints = [joint for joint in required_joints if joint not in data.joints]
        if missing_joints:
            logger.warning(f"Missing required joints: {missing_joints}")
            return {
                "overall_score": 0,
                "details": {
                    "shoulder_abduction": False,
                    "elbow_flexion": False,
                    "elbow_lower": False,
                    "foot_direction_aligned": False,
                    "proximal_to_distal_sequence": False,
                    "hip_forward_shift": False,
                    "trunk_rotation_completed": False
                },
                "error": f"Missing required joints: {', '.join(missing_joints)}"
            }
        
        # Convert from frontend format to NumPy arrays
        for joint_name, joint_data in data.joints.items():
            # Create a numpy array of shape (T, 2) where T is the number of frames
            points = np.array([[point.x, point.y] for point in joint_data])
            keypoints[joint_name] = points
        
        frame_count = len(next(iter(data.joints.values())))
        logger.info(f"Processing {frame_count} frames of motion data")
        
        keypoints = align_keypoints_with_interpolation(keypoints, frame_count)
        
        # Run the evaluation
        results = evaluate_swing_rules(keypoints, dominant_side=data.dominant_side)
        
        # Convert NumPy types to standard Python types
        results = convert_numpy_types(results)
        
        # Format results for display
        formatted_results = {
            "overall_score": sum(1 for v in results.values() if v) / len(results) * 100,
            "details": results
        }
        
        logger.info(f"Technique analysis complete. Overall score: {formatted_results['overall_score']:.1f}%")
        return formatted_results
    
    except Exception as e:
        logger.error(f"Error during technique analysis: {str(e)}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Analysis failed: {str(e)}")

@app.post("/analyze/comparison")
async def analyze_comparison(data: Dict[str, FrameJoints]):
    """
    Compare user technique against model or another video
    Expected keys: 'user', 'reference'
    """
    try:
        logger.info("Received comparison analysis request")
        
        if "user" not in data or "reference" not in data:
            logger.error("Missing required 'user' or 'reference' data in comparison request")
            raise HTTPException(status_code=400, detail="Both 'user' and 'reference' data are required")
        
        user_results = await analyze_technique(data["user"])
        reference_results = await analyze_technique(data["reference"])
        
        # Calculate similarity scores between user and reference
        similarity = {}
        for rule in user_results["details"]:
            similarity[rule] = user_results["details"][rule] == reference_results["details"][rule]
        
        response = {
            "user_score": user_results["overall_score"],
            "reference_score": reference_results["overall_score"],
            "similarity": similarity,
            "user_details": user_results["details"],
            "reference_details": reference_results["details"]
        }
        
        logger.info(f"Comparison complete. User score: {response['user_score']:.1f}%, Reference score: {response['reference_score']:.1f}%")
        return response
    
    except Exception as e:
        logger.error(f"Error during comparison analysis: {str(e)}")
        logger.error(traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"Comparison failed: {str(e)}")

@app.get("/")
async def root():
    return {"status": "Server is running", "version": "1.0.0"}

if __name__ == "__main__":
    import uvicorn
    
    logger.info("Starting MoveInsight Analysis Server...")
    
    # Configure Uvicorn with appropriate settings
    config = uvicorn.Config(
        app=app,
        host="0.0.0.0",  # CRITICAL CHANGE: Listen on all interfaces, not just localhost
        port=8000,
        log_level="info",
        timeout_keep_alive=65,  # Keep connections alive longer
        limit_concurrency=10    # Limit concurrent connections to prevent overload
    )
    
    server = uvicorn.Server(config)
    server.run()
</file>

<file path="MoveInsightServer/overhead_diagnose.py">
# 需要判断的7个技术指标如下：
#   1. **shoulder_abduction**: 不要掉肘；
#   2. **elbow_flexion**: 肘关节收紧；
#   3. **elbow_lower**: 持拍手的肘部低于非持拍手的肘部；
#   4. **foot_direction_aligned**: 双脚的脚尖方向是否一致；
#   5. **proximal_to_distal_sequence**: 挥拍阶段上肢发力的顺序是否正确；
#   6. **hip_forward_shift**: 挥拍阶段髋部前移；
#   7. **trunk_rotation_completed**: 挥拍阶段躯干转体是否充分。

import numpy as np
def evaluate_swing_rules(keypoints, dominant_side='Right'):
    """
    KEYPOINTS 输入说明：

    本系统使用的关键点数据格式为 Python 字典（dict），名为 `keypoints`，其结构如下：

    keypoints = {
        'RightShoulder': np.ndarray of shape (T, 2),
        'LeftShoulder':  np.ndarray of shape (T, 2),
        'RightElbow':    np.ndarray of shape (T, 2),
        'LeftElbow':     np.ndarray of shape (T, 2),
        'RightWrist':    np.ndarray of shape (T, 2),
        'RightHand':     np.ndarray of shape (T, 2),  # 可选
        'RightHip':      np.ndarray of shape (T, 2),
        'LeftHip':       np.ndarray of shape (T, 2),
        'RightHeel':     np.ndarray of shape (T, 2),
        'RightToe':      np.ndarray of shape (T, 2),
        'LeftHeel':      np.ndarray of shape (T, 2),
        'LeftToe':       np.ndarray of shape (T, 2)
    }

    说明：
    - 每个 key 是关键点的英文全称；
    - 每个 value 是一个 numpy 数组，形状为 (T, 2)，其中：
        - T 表示视频的帧数；
        - 每一行是该帧的 (X, Y) 坐标；
        - 坐标单位可为像素或归一化值，但整组数据应保持一致。

    数据来源：
    - 可通过 Apple Vision, MediaPipe, OpenPose 等人体姿态识别工具生成；
    - 你应根据模型输出映射 keypoint 编号，统一重命名为上述英文标准名；
    - 可在中间添加字典映射，例如：
        joint_map = {0: 'RightShoulder', 1: 'RightElbow', ...}
    """
    result = {}
    D = dominant_side
    ND = 'Left' if D == 'Right' else 'Right'
    T = keypoints[f'{D}Shoulder'].shape[0]

    def angle_between(v1, v2):
        unit_v1 = v1 / (np.linalg.norm(v1) + 1e-6)
        unit_v2 = v2 / (np.linalg.norm(v2) + 1e-6)
        dot = np.clip(np.dot(unit_v1, unit_v2), -1.0, 1.0)
        return np.degrees(np.arccos(dot))

    def joint_angle(A, B, C):
        v1 = A - B
        v2 = C - B
        return angle_between(v1, v2)

    # Direction-based phase split using elbow movement
    elbow_x_vel = np.zeros(T)
    elbow_x_vel[1:] = keypoints[f'{D}Elbow'][1:, 0] - keypoints[f'{D}Elbow'][:-1, 0]

    # Apply smoothing to reduce noise (elbow is more active than shoulder, so medium window)
    window_size = min(5, T - 1)
    if window_size > 2:
        smoothed_vel = np.convolve(elbow_x_vel, np.ones(window_size) / window_size, mode='valid')
        padding = np.zeros(T - len(smoothed_vel))
        smoothed_vel = np.concatenate((padding, smoothed_vel))
    else:
        smoothed_vel = elbow_x_vel

    # Find the point where velocity changes from negative to positive
    # This indicates the elbow stops moving backward and starts moving forward
    swing_start = 0
    for t in range(1, T):
        if smoothed_vel[t - 1] < 0 and smoothed_vel[t] > 0:
            swing_start = t
            break

    # Fallback if no clear turning point found
    if swing_start == 0:
        vel_threshold = np.max(np.abs(smoothed_vel)) * 0.15
        for t in range(1, T):
            if smoothed_vel[t] > vel_threshold:
                swing_start = t
                break

        if swing_start == 0:
            swing_start = T // 2

    swing_end = T - 1

    # Keep the degenerate case check
    if swing_start >= swing_end:
        result.update({
            'shoulder_abduction': False,
            'elbow_flexion': False,
            'elbow_lower': False,
            'foot_direction_aligned': False,
            'proximal_to_distal_sequence': False,
            'hip_forward_shift': False,
            'trunk_rotation_completed': False
        })
        return result

    # 引拍期
    shoulder_angles = []
    elbow_angles = []
    for t in range(swing_start):
        shoulder_angles.append(joint_angle(keypoints[f'{D}Hip'][t], keypoints[f'{D}Shoulder'][t], keypoints[f'{D}Elbow'][t]))
        elbow_angles.append(joint_angle(keypoints[f'{D}Shoulder'][t], keypoints[f'{D}Elbow'][t], keypoints[f'{D}Wrist'][t]))

    result['shoulder_abduction'] = np.any((np.array(shoulder_angles) >= 60) & (np.array(shoulder_angles) <= 90))
    result['elbow_flexion'] = np.any(np.array(elbow_angles) < 90)
    result['elbow_lower'] = np.any(keypoints[f'{D}Elbow'][:swing_start, 1] > keypoints[f'{ND}Elbow'][:swing_start, 1])

    # foot direction
    v_r = keypoints['RightToe'][:swing_start] - keypoints['RightHeel'][:swing_start]
    v_l = keypoints['LeftToe'][:swing_start] - keypoints['LeftHeel'][:swing_start]
    foot_angles = [angle_between(vr, vl) for vr, vl in zip(v_r, v_l)]
    result['foot_direction_aligned'] = np.any(np.array(foot_angles) < 30)

    # 挥拍期
    def get_angle_series(A, B, C):
        return np.array([joint_angle(A[t], B[t], C[t]) for t in range(T)])

    shoulder_seq = get_angle_series(keypoints[f'{D}Hip'], keypoints[f'{D}Shoulder'], keypoints[f'{D}Elbow'])
    elbow_seq = get_angle_series(keypoints[f'{D}Shoulder'], keypoints[f'{D}Elbow'], keypoints[f'{D}Wrist'])
    wrist_seq = get_angle_series(keypoints[f'{D}Elbow'], keypoints[f'{D}Wrist'],
                                 keypoints[f'{D}Hand'] if f'{D}Hand' in keypoints else keypoints[f'{D}Wrist'])

    vel_shoulder = np.abs(np.diff(shoulder_seq))
    vel_elbow = np.abs(np.diff(elbow_seq))
    vel_wrist = np.abs(np.diff(wrist_seq))

    result['proximal_to_distal_sequence'] = False
    if swing_start < len(vel_shoulder):
        t_s = np.argmax(vel_shoulder[swing_start:]) + swing_start
        t_e = np.argmax(vel_elbow[swing_start:]) + swing_start
        t_w = np.argmax(vel_wrist[swing_start:]) + swing_start
        result['proximal_to_distal_sequence'] = t_s < t_e #手腕的识别不准先去掉了，只看了肩和肘的

    hip_center_x = 0.5 * (keypoints[f'{D}Hip'][:, 0] + keypoints[f'{ND}Hip'][:, 0])
    hip_range = np.max(hip_center_x) - np.min(hip_center_x)
    result['hip_forward_shift'] = hip_range >= 0.10

    dist_init = np.linalg.norm(keypoints[f'{D}Shoulder'][swing_start] - keypoints[f'{ND}Shoulder'][swing_start])
    dist_min = np.min([
        np.linalg.norm(keypoints[f'{D}Shoulder'][t] - keypoints[f'{ND}Shoulder'][t])
        for t in range(swing_start, swing_end + 1)
    ])
    result['trunk_rotation_completed'] = (dist_init - dist_min) / (dist_init + 1e-6) >= 0.5

    return result

def align_keypoints_with_interpolation(joint_data, frame_count):
    keypoints = {}

    for name, points in joint_data.items():
        pts = np.array(points)  # shape: (n, 2)
        n = len(pts)

        if n == frame_count:
            keypoints[name] = pts
        elif n >= frame_count - 2:
            # ⚠️ 允许最多缺 1-2 帧，尝试修复

            # 创建一个 shape=(frame_count, 2) 的空数组
            filled = np.full((frame_count, 2), np.nan)

            # 填入已知帧（假设 joint_data 是顺序连续 append 的）
            valid_indices = np.linspace(0, frame_count - 1, n, dtype=int)
            filled[valid_indices] = pts

            # 找出缺失帧，用线性插值补齐
            for dim in range(2):  # 对X和Y分别插值
                valid = ~np.isnan(filled[:, dim])
                if np.sum(valid) < 2:
                    print(f"❌ 无法插值 {name}，有效点太少")
                    break
                filled[:, dim] = np.interp(
                    np.arange(frame_count),
                    np.where(valid)[0],
                    filled[valid, dim]
                )

            keypoints[name] = filled

        else:
            print(f"⚠️ {name} 缺失太多（{n}/{frame_count}），丢弃该关键点")

    return keypoints

# #########################################测试函数功能############################################
T = 100
def gen_mock_data(x_shift=0.0):
    # Linear motion with optional shift
    return np.stack([np.linspace(0, 1, T) + x_shift, np.linspace(0.5, 0.5, T)], axis=1)

keypoints = {
    'RightShoulder': gen_mock_data(0.1),
    'LeftShoulder': gen_mock_data(-0.1),
    'RightElbow': gen_mock_data(0.2),
    'LeftElbow': gen_mock_data(-0.2),
    'RightWrist': gen_mock_data(0.3),
    'RightHand': gen_mock_data(0.35),
    'RightHip': gen_mock_data(0.0),
    'LeftHip': gen_mock_data(-0.05),
    'RightToe': gen_mock_data(0.2),
    'RightHeel': gen_mock_data(0.1),
    'LeftToe': gen_mock_data(-0.2),
    'LeftHeel': gen_mock_data(-0.1),
}

# Evaluate rules
results = evaluate_swing_rules(keypoints, dominant_side='Right')
print(results)
</file>

<file path="MoveInsight/Assets.xcassets/AccentColor.colorset/Contents.json">
{
  "colors" : [
    {
      "idiom" : "universal"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}
</file>

<file path="MoveInsight/Assets.xcassets/player_shuttle_distance.imageset/Contents.json">
{
  "images" : [
    {
      "filename" : "Screenshot 2025-04-25 at 20.31.05.png",
      "idiom" : "universal",
      "scale" : "1x"
    },
    {
      "idiom" : "universal",
      "scale" : "2x"
    },
    {
      "idiom" : "universal",
      "scale" : "3x"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}
</file>

<file path="MoveInsight/Assets.xcassets/velocity_profile_chart.imageset/Contents.json">
{
  "images" : [
    {
      "filename" : "velocity_profile_chart.png",
      "idiom" : "universal",
      "scale" : "1x"
    },
    {
      "idiom" : "universal",
      "scale" : "2x"
    },
    {
      "idiom" : "universal",
      "scale" : "3x"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}
</file>

<file path="MoveInsight/Assets.xcassets/Contents.json">
{
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}
</file>

<file path="MoveInsight/DepthAnythingV2SmallF16.mlpackage/Manifest.json">
{
    "fileFormatVersion": "1.0.0",
    "itemInfoEntries": {
        "20D05BA4-5503-4673-8F11-11EF6A25EE9D": {
            "author": "com.apple.CoreML",
            "description": "CoreML Model Weights",
            "name": "weights",
            "path": "com.apple.CoreML/weights"
        },
        "D698F85A-E9D9-47BF-8C1B-5A441F139CAA": {
            "author": "com.apple.CoreML",
            "description": "CoreML Model Specification",
            "name": "model.mlmodel",
            "path": "com.apple.CoreML/model.mlmodel"
        }
    },
    "rootModelIdentifier": "D698F85A-E9D9-47BF-8C1B-5A441F139CAA"
}
</file>

<file path="MoveInsight/en.lproj/Localizable.strings">
// Main navigation
"Home" = "Home";
"Training" = "Training";
"Videos" = "Videos";
"Messages" = "Messages";

// Upload functionality
"Upload Video" = "Upload Video";
"Uploading..." = "Uploading...";
"Close" = "Close";
"Upload Match Video" = "Upload Match Video";
"Upload Training Video" = "Upload Training Video";
"Match Video" = "Match Video";
"Training Video" = "Training Video";
"Loading Video..." = "Loading Video...";
"Preparing video..." = "Preparing video...";

// Permissions
"Photo Library Access Required" = "Photo Library Access Required";
"Permission to access your photo library is required to upload videos. Please grant access in Settings." = "Permission to access your photo library is required to upload videos. Please grant access in Settings.";
"Go to Settings" = "Go to Settings";
"Cancel" = "Cancel";

// Home View
"Good morning," = "Good morning,";
"Match Performance" = "Match Performance";
"/ last week" = "/ last week";
"Well done on swing path!" = "Well done on swing path!";
"Match History" = "Match History";
"Technicals" = "Technicals";
"Training Goals" = "Training Goals";
"Tutorials Specifically For You" = "Tutorials Specifically For You";

// Chart months
"Jan" = "Jan";
"Feb" = "Feb";
"Mar" = "Mar";
"Apr" = "Apr";
"May" = "May";

// Placeholder screens
"Training Screen" = "Training Screen";
"Upload Screen" = "Upload Screen";
"Videos Screen" = "Videos Screen";
"Messages Screen" = "Messages Screen";

// Numeric values (formats can be localized)
"2.3%" = "2.3%";
"4.3" = "4.3";

// Details screens
"Technicals Detail" = "Technicals Detail";
"Training Goals Detail" = "Training Goals Detail";
</file>

<file path="MoveInsight/Preview Content/Preview Assets.xcassets/Contents.json">
{
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}
</file>

<file path="MoveInsight/zh-Hans.lproj/Localizable.strings">
// Main navigation
"Home" = "首页";
"Training" = "训练";
"Videos" = "视频";
"Messages" = "消息";

// Upload functionality
"Upload Video" = "上传视频";
"Uploading..." = "上传中...";
"Close" = "关闭";
"Upload Match Video" = "上传比赛视频";
"Upload Training Video" = "上传训练视频";
"Match Video" = "比赛视频";
"Training Video" = "训练视频";
"Loading Video..." = "加载视频中...";
"Preparing video..." = "准备视频中...";

// Permissions
"Photo Library Access Required" = "需要访问照片库";
"Permission to access your photo library is required to upload videos. Please grant access in Settings." = "上传视频需要访问您的照片库。请在设置中授予权限。";
"Go to Settings" = "前往设置";
"Cancel" = "取消";

// Home View
"Good morning," = "早上好，";
"Match Performance" = "比赛表现";
"/ last week" = "/ 上周";
"Well done on swing path!" = "挥杆轨迹很棒！";
"Match History" = "比赛历史";
"Technicals" = "技术分析";
"Training Goals" = "训练目标";
"Tutorials Specifically For You" = "专为您定制的教程";

// Chart months
"Jan" = "一月";
"Feb" = "二月";
"Mar" = "三月";
"Apr" = "四月";
"May" = "五月";

// Placeholder screens
"Training Screen" = "训练界面";
"Upload Screen" = "上传界面";
"Videos Screen" = "视频界面";
"Messages Screen" = "消息界面";

// Numeric values (formats can be localized)
"2.3%" = "2.3%";
"4.3" = "4.3";

// Details screens
"Technicals Detail" = "技术分析详情";
"Training Goals Detail" = "训练目标详情";
</file>

<file path="MoveInsight/ColorManager.swift">
import SwiftUI

struct ColorManager {
    /// Brand purple color used in MoveInsight logo (#5C2D91)
    static let accentColor = Color(hex: "5C2D91")
    
    // Dynamic background: black in dark mode, white in light mode.
    static var background: Color {
        Color(UIColor { traitCollection in
            traitCollection.userInterfaceStyle == .dark ? UIColor.black : UIColor.white
        })
    }
    
    // Primary text color: white in dark mode, black in light mode.
    static var textPrimary: Color {
        Color(UIColor { traitCollection in
            traitCollection.userInterfaceStyle == .dark ? UIColor.white : UIColor.black
        })
    }
    
    // Secondary text color: light gray in dark mode, dark gray in light mode.
    static var textSecondary: Color {
        Color(UIColor { traitCollection in
            traitCollection.userInterfaceStyle == .dark ? UIColor.lightGray : UIColor.darkGray
        })
    }
    
    // Card background: a subtle gray that adapts to light/dark mode.
    static var cardBackground: Color {
        Color(UIColor { traitCollection in
            if traitCollection.userInterfaceStyle == .dark {
                return UIColor.systemGray6
            } else {
                return UIColor.systemGray5
            }
        })
    }
    
    /// Plus button color: white in light mode, black in dark mode.
    static var uploadPlusButtonColor: Color {
        Color(UIColor { traitCollection in
            traitCollection.userInterfaceStyle == .dark ? UIColor.black : UIColor.white
        })
    }
}

extension Color {
    init(hex: String) {
        let hex = hex.trimmingCharacters(in: CharacterSet.alphanumerics.inverted)
        var int: UInt64 = 0
        Scanner(string: hex).scanHexInt64(&int)
        let a, r, g, b: UInt64
        switch hex.count {
        case 3: // RGB (12-bit)
            (a, r, g, b) = (255, (int >> 8) * 17,
                                 (int >> 4 & 0xF) * 17,
                                 (int & 0xF) * 17)
        case 6: // RGB (24-bit)
            (a, r, g, b) = (255,
                           int >> 16,
                           int >> 8 & 0xFF,
                           int & 0xFF)
        case 8: // ARGB (32-bit)
            (a, r, g, b) = (int >> 24,
                           int >> 16 & 0xFF,
                           int >> 8 & 0xFF,
                           int & 0xFF)
        default:
            (a, r, g, b) = (255, 0, 0, 0) // fallback: opaque black
        }

        self.init(
            .sRGB,
            red: Double(r) / 255,
            green: Double(g) / 255,
            blue: Double(b) / 255,
            opacity: Double(a) / 255
        )
    }
}
</file>

<file path="MoveInsight/CombinedVideo3DView.swift">
import SwiftUI
import AVKit
import Vision
import simd

struct CombinedVideo3DView: View {
    @ObservedObject var baseViewModel: VideoPlayerViewModel
    @ObservedObject var overlayViewModel: VideoPlayerViewModel
    
    // Playback control state
    @State private var currentTime: Double = 0
    @State private var timeObserver: Any? = nil
    private var duration: Double { baseViewModel.asset.duration.seconds }
    private let frameStep: Double = 1.0 / 30.0

    var body: some View {
        ZStack {
            ColorManager.background.ignoresSafeArea()

            VStack(spacing: 0) {
                ZStack {
                    ColorManager.background.ignoresSafeArea()

                    if baseViewModel.isVideoReady && overlayViewModel.isVideoReady {
                        // Just show the SceneView - no toggles or previews
                        SceneView3D(
                            pose3DBodies: combinedPose3DBodies,
                            bodyConnections: baseViewModel.bodyConnections
                        )
                        .frame(maxWidth: .infinity, maxHeight: .infinity)
                    } else {
                        ProgressView("Loading 3D view...")
                            .tint(ColorManager.accentColor)
                    }
                }
                .onAppear {
                    setupTimeObserver()
                    // Start both videos: base audible, overlay muted
                    baseViewModel.play()
                    overlayViewModel.play()
                    overlayViewModel.player.isMuted = true
                }
                .onDisappear {
                    removeTimeObserver()
                    baseViewModel.pause()
                    overlayViewModel.pause()
                }

                // Shared controls for both videos
                controlBar
            }
        }
    }
    
    private var combinedPose3DBodies: [Pose3DBody] {
        baseViewModel.pose3DBodies + overlayViewModel.pose3DBodies
    }

    private var controlBar: some View {
        HStack(spacing: 20) {
            Button(action: togglePlayPause) {
                Image(systemName: baseViewModel.isPlaying ? "pause.fill" : "play.fill")
            }

            Button(action: { step(by: -1) }) {
                Image(systemName: "backward.frame")
            }

            Button(action: { step(by: 1) }) {
                Image(systemName: "forward.frame")
            }

            Slider(
                value: $currentTime,
                in: 0...max(0.1, duration), // Ensure non-zero range
                onEditingChanged: { editing in
                    if !editing {
                        seek(to: currentTime)
                    }
                }
            )
        }
        .padding()
        .background(ColorManager.background.opacity(0.7))
    }

    // MARK: - Playback helpers controlling both videos
    private func togglePlayPause() {
        if baseViewModel.isPlaying {
            baseViewModel.pause()
            overlayViewModel.pause()
        } else {
            baseViewModel.play()
            overlayViewModel.play()
        }
    }

    private func step(by frames: Int) {
        let newTime = max(0, min(duration, currentTime + Double(frames) * frameStep))
        seek(to: newTime)
    }

    private func seek(to timeSec: Double) {
        let cmTime = CMTime(seconds: timeSec, preferredTimescale: 600)

        // Pause both players
        baseViewModel.pause()
        overlayViewModel.pause()

        // Seek both players exactly
        baseViewModel.player.seek(to: cmTime, toleranceBefore: .zero, toleranceAfter: .zero)
        overlayViewModel.player.seek(to: cmTime, toleranceBefore: .zero, toleranceAfter: .zero)

        // Update state
        baseViewModel.isPlaying = false
        overlayViewModel.isPlaying = false
        currentTime = timeSec

        // Briefly unpause to update poses, then pause again
        baseViewModel.play()
        overlayViewModel.play()
        DispatchQueue.main.asyncAfter(deadline: .now() + frameStep) {
            baseViewModel.pause()
            overlayViewModel.pause()
        }
    }

    private func setupTimeObserver() {
        guard timeObserver == nil else { return }
        let interval = CMTime(seconds: frameStep, preferredTimescale: 600)
        let obs = baseViewModel.player.addPeriodicTimeObserver(
            forInterval: interval, queue: .main
        ) { time in
            currentTime = time.seconds
        }
        timeObserver = obs
    }

    private func removeTimeObserver() {
        if let obs = timeObserver {
            baseViewModel.player.removeTimeObserver(obs)
            timeObserver = nil
        }
    }
}
</file>

<file path="MoveInsight/CustomTabBar.swift">
import SwiftUI

// MARK: - Custom Tab Bar
struct CustomTabBar: View {
    @Binding var selectedTab: Int

    var body: some View {
        EvenlySpacedTabBar(selectedTab: $selectedTab)
    }
}

// MARK: - Evenly Spaced Tab Bar
struct EvenlySpacedTabBar: View {
    @Binding var selectedTab: Int
    
    var body: some View {
        HStack {
            Spacer()
            
            // Home button
            TabBarButtonEvenly(iconName: "house.fill", isSelected: selectedTab == 0) {
                selectedTab = 0
            }
            
            Spacer()
            
            // Training button
            TabBarButtonEvenly(iconName: "figure.run", isSelected: selectedTab == 1) {
                selectedTab = 1
            }
            
            Spacer()
            
            // Plus (upload) button – uses dynamic color for plus icon.
            Button(action: {
                // In this updated design, the Upload tab is directly rendered.
                selectedTab = 2
            }) {
                ZStack {
                    Circle()
                        .fill(ColorManager.accentColor)
                        .frame(width: 44, height: 44)
                    
                    Image(systemName: "plus")
                        .font(.system(size: 18, weight: .bold))
                        .foregroundColor(ColorManager.uploadPlusButtonColor)
                }
            }
            
            Spacer()
            
            // Videos button
            TabBarButtonEvenly(iconName: "play.rectangle.fill", isSelected: selectedTab == 3) {
                selectedTab = 3
            }
            
            Spacer()
            
            // Messages button
            TabBarButtonEvenly(iconName: "message.fill", isSelected: selectedTab == 4) {
                selectedTab = 4
            }
            
            Spacer()
        }
        .padding(.vertical, 10)
        .background(ColorManager.background)
        .overlay(
            Rectangle()
                .frame(height: 1)
                .foregroundColor(ColorManager.textSecondary.opacity(0.3)),
            alignment: .top
        )
    }
}

// MARK: - Tab Bar Button for Evenly Spaced Layout
struct TabBarButtonEvenly: View {
    let iconName: String
    let isSelected: Bool
    let action: () -> Void

    var body: some View {
        Button(action: action) {
            Image(systemName: iconName)
                .font(.system(size: 20))
                .foregroundColor(isSelected ? ColorManager.accentColor : ColorManager.textPrimary)
        }
    }
}

// MARK: - Legacy Tab Bar Button Component (kept for backward compatibility)
struct TabBarButton: View {
    let iconName: String
    let title: LocalizedStringKey
    let isSelected: Bool
    let action: () -> Void

    var body: some View {
        Button(action: action) {
            VStack(spacing: 3) {
                Image(systemName: iconName)
                    .font(.system(size: 18))
                    .foregroundColor(isSelected ? ColorManager.accentColor : ColorManager.textPrimary)

                Text(title)
                    .font(.system(size: 11))
                    .foregroundColor(isSelected ? ColorManager.accentColor : ColorManager.textPrimary)
            }
            .frame(maxWidth: .infinity)
        }
    }
}
</file>

<file path="MoveInsight/DepthEstimationService.swift">
import CoreML
import Vision
import AVFoundation
import Accelerate
import UIKit

class DepthEstimationService {
    private var depthModel: MLModel?
    
    init() {
        do {
            let modelURL = Bundle.main.url(forResource: "DepthAnythingV2SmallF16", withExtension: "mlmodelc")!
            let config = MLModelConfiguration()
            self.depthModel = try MLModel(contentsOf: modelURL, configuration: config)
            print("Loaded depth model successfully.")
        } catch {
            print("Failed to load depth model: \(error)")
        }
    }
    
    func estimateDepth(from pixelBuffer: CVPixelBuffer) -> CVPixelBuffer? {
        guard let model = depthModel else {
            print("Depth model not loaded")
            return nil
        }
        
        do {
            // Resize according to model requirements
            let resizedPixelBuffer = resizePixelBufferToRequiredSize(pixelBuffer)
            let width = CVPixelBufferGetWidth(resizedPixelBuffer)
            let height = CVPixelBufferGetHeight(resizedPixelBuffer)
            print("Resized to \(width) x \(height)")
            
            // Create MLFeatureValue for the image
            let imageFeatureValue = MLFeatureValue(pixelBuffer: resizedPixelBuffer)
            
            // Create input feature dictionary
            let inputFeatures = try MLDictionaryFeatureProvider(dictionary: ["image": imageFeatureValue])
            
            // Make prediction
            let outputFeatures = try model.prediction(from: inputFeatures)
            
            // Extract the depth map
            if let depthFeatureValue = outputFeatures.featureValue(for: "depth"),
               let depthPixelBuffer = depthFeatureValue.imageBufferValue {
                return depthPixelBuffer
            } else {
                print("Failed to extract depth output")
                return nil
            }
        } catch {
            print("Depth estimation failed: \(error)")
            return nil
        }
    }
    
    // Resize according to specific model requirements
    private func resizePixelBufferToRequiredSize(_ pixelBuffer: CVPixelBuffer) -> CVPixelBuffer {
        let width = CVPixelBufferGetWidth(pixelBuffer)
        let height = CVPixelBufferGetHeight(pixelBuffer)
        
        // Target dimensions
        // Width should be 518, height should be 392 (as per your example)
        let targetWidth = 518
        let targetHeight = 392
        
        // Create a CIImage from the pixel buffer
        let ciImage = CIImage(cvPixelBuffer: pixelBuffer)
        
        // Scale the image
        let scaleX = CGFloat(targetWidth) / CGFloat(width)
        let scaleY = CGFloat(targetHeight) / CGFloat(height)
        let scaledImage = ciImage.transformed(by: CGAffineTransform(scaleX: scaleX, y: scaleY))
        
        // Create a new pixel buffer
        var newPixelBuffer: CVPixelBuffer?
        let options = [
            kCVPixelBufferCGImageCompatibilityKey: true,
            kCVPixelBufferCGBitmapContextCompatibilityKey: true
        ] as CFDictionary
        
        CVPixelBufferCreate(kCFAllocatorDefault,
                           targetWidth,
                           targetHeight,
                           kCVPixelFormatType_32BGRA,
                           options,
                           &newPixelBuffer)
        
        guard let outputPixelBuffer = newPixelBuffer else {
            return pixelBuffer // Return original if resize fails
        }
        
        // Render the scaled CIImage to the new pixel buffer
        let context = CIContext()
        context.render(scaledImage, to: outputPixelBuffer)
        
        return outputPixelBuffer
    }
    
    // Convert depth pixel buffer to UIImage for visualization
    func depthMapToImage(from depthBuffer: CVPixelBuffer) -> UIImage? {
        CVPixelBufferLockBaseAddress(depthBuffer, .readOnly)
        defer { CVPixelBufferUnlockBaseAddress(depthBuffer, .readOnly) }
        
        // For Grayscale16Half format, we need to convert it to a format UIImage can use
        let width = CVPixelBufferGetWidth(depthBuffer)
        let height = CVPixelBufferGetHeight(depthBuffer)
        
        // Create a CIImage from the depth buffer
        var ciImage: CIImage?
        if let colorSpace = CGColorSpace(name: CGColorSpace.linearGray) {
            ciImage = CIImage(cvImageBuffer: depthBuffer, options: [.colorSpace: colorSpace])
        } else {
            ciImage = CIImage(cvImageBuffer: depthBuffer)
        }
        
        guard let image = ciImage else { return nil }
        
        // Apply visualization filters to make depth more visible
        let normalizedImage = image.applyingFilter("CIColorControls", parameters: [
            kCIInputContrastKey: 1.5,
            kCIInputBrightnessKey: 0.2
        ])
        
        // Create a colored version using the turbo colormap
        let coloredImage = normalizedImage.applyingFilter("CIColorMap", parameters: [
            "inputGradientImage": createTurboColormap()
        ])
        
        // Convert to UIImage
        let context = CIContext()
        if let cgImage = context.createCGImage(coloredImage, from: coloredImage.extent) {
            return UIImage(cgImage: cgImage)
        }
        
        return nil
    }
    
    // Create a turbo colormap for better depth visualization
    private func createTurboColormap() -> CIImage {
        let colors: [(CGFloat, CGFloat, CGFloat)] = [
            (0.18995, 0.07176, 0.23217), // Dark blue
            (0.19483, 0.22800, 0.47607), // Blue
            (0.01555, 0.44879, 0.69486), // Light blue
            (0.12943, 0.65563, 0.67862), // Cyan
            (0.33486, 0.81853, 0.39915), // Green
            (0.66724, 0.88581, 0.25420), // Yellow-green
            (0.90480, 0.91255, 0.10421), // Yellow
            (0.99796, 0.68829, 0.02774), // Orange
            (0.95909, 0.37228, 0.01549), // Red-orange
            (0.73683, 0.01779, 0.01820)  // Dark red
        ]
        
        let width = 256
        let gradientImage = CIImage(color: CIColor(red: 0, green: 0, blue: 0)).cropped(to: CGRect(x: 0, y: 0, width: width, height: 1))
        
        var result = gradientImage
        
        // Create gradient segments
        for i in 0..<(colors.count-1) {
            let startColor = CIColor(red: colors[i].0, green: colors[i].1, blue: colors[i].2)
            let endColor = CIColor(red: colors[i+1].0, green: colors[i+1].1, blue: colors[i+1].2)
            
            let startX = (width * i) / (colors.count - 1)
            let endX = (width * (i + 1)) / (colors.count - 1)
            
            let gradient = CIFilter(name: "CILinearGradient", parameters: [
                "inputPoint0": CIVector(x: CGFloat(startX), y: 0),
                "inputPoint1": CIVector(x: CGFloat(endX), y: 0),
                "inputColor0": startColor,
                "inputColor1": endColor
            ])!.outputImage!
            
            // Blend with previous result
            result = result.applyingFilter("CISourceOverCompositing", parameters: [
                "inputBackgroundImage": gradient
            ])
        }
        
        return result
    }
}
</file>

<file path="MoveInsight/ModelVideoLoader.swift">
import Foundation
import AVKit

// This class helps manage model videos in the app's bundle
class ModelVideoLoader {
    static let shared = ModelVideoLoader()
    
    // Map of technique names to their video filenames (without extension)
    private let techniqueVideoMap: [String: String] = [
        "Underhand Clear": "underhand_clear_model",
        // Other techniques would be added here as they become available
    ]
    
    private init() {
        // Log available model videos on initialization
        print("ModelVideoLoader initialized with techniques: \(techniqueVideoMap.keys.joined(separator: ", "))")
    }
    
    // Get the URL for a specific technique's model video
    func getModelVideoURL(for technique: String) -> URL? {
        // Try to find the exact technique name in our map
        let cleanTechniqueName = technique.trimmingCharacters(in: .whitespacesAndNewlines)
        
        if let filename = techniqueVideoMap[cleanTechniqueName] {
            if let url = Bundle.main.url(forResource: filename, withExtension: "mov") {
                print("Found model video for \(cleanTechniqueName) at \(url.path)")
                return url
            }
        }
        
        // Try with a normalized technique name (lowercase, underscores)
        let normalizedName = cleanTechniqueName.lowercased().replacingOccurrences(of: " ", with: "_")
        if let url = Bundle.main.url(forResource: normalizedName, withExtension: "mov") {
            print("Found model video using normalized name \(normalizedName)")
            return url
        }
        
        // Special case for backhand clear (our only implemented video currently)
        if cleanTechniqueName.lowercased().contains("backhand") {
            if let fallbackURL = Bundle.main.url(forResource: "backhand_clear_model", withExtension: "mov") {
                print("Found underhand clear model video as fallback")
                return fallbackURL
            }
        }
        
        print("No model video found for technique: \(technique)")
        return nil
    }
    
    // Check if a model video exists for a specific technique
    func hasModelVideo(for technique: String) -> Bool {
        return getModelVideoURL(for: technique) != nil
    }
    
    // Create a VideoPlayerViewModel for a model video
    func createModelVideoViewModel(for technique: String) -> VideoPlayerViewModel? {
        guard let videoURL = getModelVideoURL(for: technique) else {
            print("Failed to create model ViewModel: no URL found for \(technique)")
            return nil
        }
        
        print("Creating model VideoPlayerViewModel for \(technique)")
        return VideoPlayerViewModel(
            videoURL: videoURL,
            videoSource: .secondary
        )
    }
}
</file>

<file path="MoveInsight/Pose3DProcessor.swift">
import Vision
import simd
import CoreVideo

class Pose3DProcessor {
    
    // Convert 2D pose point with depth to 3D
    func convert2DPoseToWorldSpace(
        pose: [VNHumanBodyPoseObservation.JointName: CGPoint],
        depthBuffer: CVPixelBuffer,
        videoSize: CGSize
    ) -> [VNHumanBodyPoseObservation.JointName: SIMD3<Float>] {
        var pose3D: [VNHumanBodyPoseObservation.JointName: SIMD3<Float>] = [:]
        
        // Get dimensions of depth buffer
        let depthWidth = CVPixelBufferGetWidth(depthBuffer)
        let depthHeight = CVPixelBufferGetHeight(depthBuffer)
        
        CVPixelBufferLockBaseAddress(depthBuffer, .readOnly)
        defer { CVPixelBufferUnlockBaseAddress(depthBuffer, .readOnly) }
        
        // Get base address assuming it's grayscale16half format
        guard let baseAddress = CVPixelBufferGetBaseAddress(depthBuffer) else {
            return [:]
        }
        
        let bytesPerRow = CVPixelBufferGetBytesPerRow(depthBuffer)
        
        for (joint, point) in pose {
            // Convert normalized coordinates to pixel coordinates in the depth buffer
            let depthX = Int(point.x * CGFloat(depthWidth))
            let depthY = Int(point.y * CGFloat(depthHeight))
            
            // Ensure coordinates are within bounds
            if depthX >= 0 && depthX < depthWidth && depthY >= 0 && depthY < depthHeight {
                // Get depth value (16-bit half float)
                let pixelAddress = baseAddress.advanced(by: depthY * bytesPerRow + depthX * 2)
                let halfFloat = pixelAddress.assumingMemoryBound(to: UInt16.self).pointee
                
                // Convert half float to float
                let depth = convertHalfToFloat(halfFloat)
                
                // Create 3D point: x, y from 2D pose, z from depth
                let x = Float(point.x * 2 - 1) // Convert 0-1 to -1 to 1
                let y = Float(1 - point.y * 2) // Convert 0-1 to 1 to -1 (y-axis flipped in 3D)
                let z = depth
                
                pose3D[joint] = SIMD3<Float>(x, y, z)
            }
        }
        
        return pose3D
    }
    
    // Helper to convert UInt16 half float to Float
    private func convertHalfToFloat(_ half: UInt16) -> Float {
        // Using a more direct bit manipulation approach
        let sign = (half & 0x8000) != 0
        let exponent = Int((half & 0x7C00) >> 10)
        let fraction = half & 0x03FF
        
        // Handle special cases
        if exponent == 0 {
            if fraction == 0 {
                return sign ? -0.0 : 0.0 // Zero
            } else {
                // Denormalized number
                var result = Float(fraction) / Float(1024)
                result *= pow(2.0, -14.0)
                return sign ? -result : result
            }
        } else if exponent == 31 {
            if fraction == 0 {
                return sign ? Float.infinity : Float.infinity
            } else {
                return Float.nan
            }
        }
        
        // Normalized number
        var result = Float(1 + Float(fraction) / 1024.0)
        result *= pow(2.0, Float(exponent - 15))
        return sign ? -result : result
    }
    
    // Processing multiple poses from a frame
    func process(
        poses: [[VNHumanBodyPoseObservation.JointName: CGPoint]],
        depthBuffer: CVPixelBuffer,
        videoSize: CGSize
    ) -> [[VNHumanBodyPoseObservation.JointName: SIMD3<Float>]] {
        return poses.map { pose in
            convert2DPoseToWorldSpace(
                pose: pose,
                depthBuffer: depthBuffer,
                videoSize: videoSize
            )
        }
    }
}
</file>

<file path="MoveInsight/SceneView3D.swift">
import SwiftUI
import Vision
import SceneKit
import simd

// Scene delegate to maintain camera position across updates
class SceneDelegate: NSObject, SCNSceneRendererDelegate, ObservableObject {
    var lastCameraTransform: SCNMatrix4?
    
    func renderer(_ renderer: SCNSceneRenderer, updateAtTime time: TimeInterval) {
        // Capture camera transform
        if let pointOfView = renderer.pointOfView {
            lastCameraTransform = pointOfView.transform
        }
    }
}

struct SceneView3D: UIViewRepresentable {
    var pose3DBodies: [Pose3DBody]
    var bodyConnections: [BodyConnection]
    @ObservedObject var sceneDelegate = SceneDelegate()
    
    // Define the root joint to use for alignment
    private let rootJoint: VNHumanBodyPoseObservation.JointName = .neck
    
    func makeUIView(context: Context) -> SCNView {
        let sceneView = SCNView()
        let scene = SCNScene()
        
        // Setup camera
        setupCamera(in: scene)
        
        // Setup lighting
        setupLighting(in: scene)
        
        // Add floor grid for better orientation
        let floor = createFloorGrid()
        floor.position = SCNVector3(0, 0, 0)
        scene.rootNode.addChildNode(floor)
        
        // Setup scene
        sceneView.scene = scene
        sceneView.backgroundColor = UIColor.systemBackground
        sceneView.allowsCameraControl = true
        sceneView.showsStatistics = false
        sceneView.delegate = sceneDelegate
        
        return sceneView
    }
    
    func updateUIView(_ uiView: SCNView, context: Context) {
        // Clear existing nodes except for camera, lights, and floor
        uiView.scene?.rootNode.childNodes.forEach { node in
            if node.camera == nil && node.light == nil && node.name != "floor" {
                node.removeFromParentNode()
            }
        }
        
        // Group poses by source
        let primaryPoses = pose3DBodies.filter { $0.videoSource == .primary }
        let secondaryPoses = pose3DBodies.filter { $0.videoSource == .secondary }

        let leftPosition = SIMD3<Float>(0, 0, 0)
        let rightPosition = SIMD3<Float>(0, 0, 0)
        
        // Get primary pose and height
        guard let primaryPose = primaryPoses.first else {
            // If only secondary pose exists, just add it without scaling
            if let secondaryPose = secondaryPoses.first {
                addSkeletonToScene(body: secondaryPose, scene: uiView.scene, position: SIMD3<Float>(0, 0, 0))
                addHeadToScene(body: secondaryPose, scene: uiView.scene, position: SIMD3<Float>(0, 0, 0))
            }
            return
        }
        
        // Calculate primary height to use for scaling
        let primaryHeight = calculateSkeletonHeight(primaryPose)
        
        // Add primary pose (left side)
        addSkeletonToScene(body: primaryPose, scene: uiView.scene, position: leftPosition)
        addHeadToScene(body: primaryPose, scene: uiView.scene, position: leftPosition)
        
        // Add secondary pose (right side) with height matching primary
        if let secondaryPose = secondaryPoses.first {
            // Get scaling factor
            let secondaryHeight = calculateSkeletonHeight(secondaryPose)
            let scaleFactor = primaryHeight / max(secondaryHeight, 0.001)
            
            // Add scaled skeleton
            addSkeletonToScene(body: secondaryPose,
                              scene: uiView.scene,
                              position: rightPosition,
                              scaleFactor: scaleFactor)
            
            // Add head with the same scaling
            addHeadToScene(body: secondaryPose,
                          scene: uiView.scene,
                          position: rightPosition,
                          scaleFactor: scaleFactor)
        }
    }
    
    // Setup camera with initial position - even closer for better visibility
    private func setupCamera(in scene: SCNScene) {
        let camera = SCNCamera()
        camera.usesOrthographicProjection = false
        camera.fieldOfView = 45 // Narrower field of view for more zoom
        camera.zNear = 0.1
        camera.zFar = 100
        
        let cameraNode = SCNNode()
        cameraNode.camera = camera
        
        // Set default camera position if no previous transform exists
        if let lastTransform = sceneDelegate.lastCameraTransform {
            // Use the last camera transform if available
            cameraNode.transform = lastTransform
        } else {
            // Position camera very close to origin for better visibility
            cameraNode.position = SCNVector3(0, 0, 3)
            cameraNode.look(at: SCNVector3(0, 0, 0))
        }
        
        scene.rootNode.addChildNode(cameraNode)
    }
    
    // Setup lighting with ambient and directional lights
    private func setupLighting(in scene: SCNScene) {
        // Add ambient light
        let ambientLight = SCNLight()
        ambientLight.type = .ambient
        ambientLight.intensity = 100
        ambientLight.color = UIColor(white: 0.5, alpha: 1.0)
        
        let ambientLightNode = SCNNode()
        ambientLightNode.light = ambientLight
        scene.rootNode.addChildNode(ambientLightNode)
        
        // Add directional light
        let directionalLight = SCNLight()
        directionalLight.type = .directional
        directionalLight.intensity = 1000
        directionalLight.castsShadow = true
        directionalLight.shadowColor = UIColor.black.withAlphaComponent(0.8)
        
        let directionalLightNode = SCNNode()
        directionalLightNode.light = directionalLight
        directionalLightNode.position = SCNVector3(5, 5, 5)
        directionalLightNode.look(at: SCNVector3(0, 0, 0))
        scene.rootNode.addChildNode(directionalLightNode)
    }
    
    // Create a floor grid for better orientation
    private func createFloorGrid() -> SCNNode {
        let gridSize: Float = 10
        let gridNode = SCNNode()
        gridNode.name = "floor"
        
        // Create a grid floor for better orientation
        for i in stride(from: -gridSize/2, through: gridSize/2, by: 0.5) {
            // X lines
            let xLine = SCNNode(geometry: SCNBox(width: CGFloat(gridSize), height: 0.001, length: 0.01, chamferRadius: 0))
            xLine.position = SCNVector3(0, 0, i)
            xLine.geometry?.firstMaterial?.diffuse.contents = i == 0 ? UIColor.blue : UIColor.gray.withAlphaComponent(0.5)
            
            // Z lines
            let zLine = SCNNode(geometry: SCNBox(width: 0.01, height: 0.001, length: CGFloat(gridSize), chamferRadius: 0))
            zLine.position = SCNVector3(i, 0, 0)
            zLine.geometry?.firstMaterial?.diffuse.contents = i == 0 ? UIColor.red : UIColor.gray.withAlphaComponent(0.5)
            
            gridNode.addChildNode(xLine)
            gridNode.addChildNode(zLine)
        }
        
        return gridNode
    }
    
    // Add the skeleton without the head
    private func addSkeletonToScene(body: Pose3DBody, scene: SCNScene?, position: SIMD3<Float>? = nil, scaleFactor: Float = 1.0) {
        guard let scene = scene else { return }
        
        // Create a parent node for this skeleton
        let skeletonNode = SCNNode()
        skeletonNode.name = "skeleton"
        
        // Find the lowest joint to place on ground
        let lowestPoint = findLowestPoint(body)
        
        // Calculate the offset to place the skeleton at the specified position
        // and with the lowest point exactly at y=0 (ground level)
        let basePosition = position ?? SIMD3<Float>(0, 0, 0)
        let verticalOffset = -lowestPoint // This will place lowest point at y=0
        
        // Create joint nodes for joints below neck only
        var jointNodes = [VNHumanBodyPoseObservation.JointName: SCNNode]()
        let upperBodyJoints: Set<VNHumanBodyPoseObservation.JointName> = [
            .leftEye, .rightEye, .leftEar, .rightEar, .nose, .neck
        ]
        
        for (jointName, posePoint) in body.joints {
            // Skip joints above shoulders
            if upperBodyJoints.contains(jointName) {
                continue
            }
            
            // Apply offset and scaling to position skeleton correctly
            let adjustedPosition = SIMD3<Float>(
                posePoint.position.x * scaleFactor + basePosition.x,
                posePoint.position.y * scaleFactor + verticalOffset * scaleFactor + basePosition.y,
                posePoint.position.z * scaleFactor + basePosition.z
            )
            
            let jointNode = createJointNode(
                position: adjustedPosition,
                source: body.videoSource
            )
            jointNodes[jointName] = jointNode
            skeletonNode.addChildNode(jointNode)
        }
        
        // Connect joints with bones, ensuring shoulder connection
        connectJoints(joints: jointNodes, in: skeletonNode, connections: bodyConnections, source: body.videoSource)
        
        // Add shoulder connection if exists in joints
        if let leftShoulder = jointNodes[.leftShoulder], let rightShoulder = jointNodes[.rightShoulder] {
            createBoneBetween(
                startPos: leftShoulder.simdPosition,
                endPos: rightShoulder.simdPosition,
                in: skeletonNode,
                source: body.videoSource
            )
        }
        
        // Add the skeleton to the scene
        scene.rootNode.addChildNode(skeletonNode)
    }
    
    // Add just the head
    private func addHeadToScene(body: Pose3DBody, scene: SCNScene?, position: SIMD3<Float>? = nil, scaleFactor: Float = 1.0) {
        guard let scene = scene else { return }
        
        // We need shoulders to place the head properly
        guard let leftShoulderJoint = body.joints[.leftShoulder],
              let rightShoulderJoint = body.joints[.rightShoulder] else {
            return
        }
        
        // Find the lowest joint to place on ground
        let lowestPoint = findLowestPoint(body)
        
        // Calculate the offset for vertical position
        let basePosition = position ?? SIMD3<Float>(0, 0, 0)
        let verticalOffset = -lowestPoint
        
        // Scale and offset shoulder positions
        let leftShoulderPos = SIMD3<Float>(
            leftShoulderJoint.position.x * scaleFactor + basePosition.x,
            leftShoulderJoint.position.y * scaleFactor + verticalOffset * scaleFactor + basePosition.y,
            leftShoulderJoint.position.z * scaleFactor + basePosition.z
        )
        
        let rightShoulderPos = SIMD3<Float>(
            rightShoulderJoint.position.x * scaleFactor + basePosition.x,
            rightShoulderJoint.position.y * scaleFactor + verticalOffset * scaleFactor + basePosition.y,
            rightShoulderJoint.position.z * scaleFactor + basePosition.z
        )
        
        // Calculate center point between shoulders
        let shoulderCenter = (leftShoulderPos + rightShoulderPos) / 2
        
        // Calculate head position just above shoulders
        let headPosition = SIMD3<Float>(
            shoulderCenter.x,                // Center between shoulders (X)
            shoulderCenter.y + 0.1,          // Just slightly above shoulders (Y)
            shoulderCenter.z                 // Same depth as shoulders (Z)
        )
        
        // Create a small head sphere with consistent size between skeletons
        let headRadius = 0.05 // Fixed size regardless of scaling
        let headGeometry = SCNSphere(radius: CGFloat(headRadius))
        let material = SCNMaterial()
        
        // Full opacity head, color based on source
        let color = body.videoSource == .primary ?
            UIColor.systemBlue :
            UIColor.systemRed
            
        material.diffuse.contents = color
        material.specular.contents = UIColor.white
        headGeometry.materials = [material]
        
        // Create head node
        let headNode = SCNNode(geometry: headGeometry)
        headNode.position = SCNVector3(headPosition.x, headPosition.y, headPosition.z)
        
        headNode.opacity = 0.6
        
        // Add the head to the scene
        scene.rootNode.addChildNode(headNode)
    }
    
    private func createJointNode(position: SIMD3<Float>, source: Pose3DBody.VideoSource) -> SCNNode {
        // Create a small sphere for the joint
        let jointGeometry = SCNSphere(radius: 0.01)
        
        let material = SCNMaterial()
        let color = source == .primary ?
            UIColor.systemBlue :
            UIColor.systemRed
        
        material.diffuse.contents = color
        material.specular.contents = UIColor.white
        jointGeometry.materials = [material]
        
        let jointNode = SCNNode(geometry: jointGeometry)
        jointNode.position = SCNVector3(
            position.x,
            position.y,
            position.z
        )
        
        // Apply opacity to entire node if secondary
        if source == .secondary {
            jointNode.opacity = 0.5
        }
        
        return jointNode
    }
    
    private func connectJoints(joints: [VNHumanBodyPoseObservation.JointName: SCNNode],
                              in parentNode: SCNNode,
                              connections: [BodyConnection],
                              source: Pose3DBody.VideoSource) {
        
        for connection in connections {
            // Skip connections involving neck
            if connection.from == .neck || connection.to == .neck {
                continue
            }
            
            guard let startNode = joints[connection.from],
                  let endNode = joints[connection.to] else {
                continue
            }
            
            let startPos = startNode.simdPosition
            let endPos = endNode.simdPosition
            
            // Create a bone between the joints
            createBoneBetween(startPos: startPos,
                             endPos: endPos,
                             in: parentNode,
                             source: source)
        }
    }
    
    private func createBoneBetween(startPos: SIMD3<Float>,
                                  endPos: SIMD3<Float>,
                                  in parentNode: SCNNode,
                                  source: Pose3DBody.VideoSource) {
        
        // Calculate the midpoint between start and end positions
        let midPoint = (startPos + endPos) / 2
        
        // Calculate the distance between points
        let distance = simd_distance(startPos, endPos)
        
        // Create a cylinder for the bone
        let boneGeometry = SCNCylinder(radius: 0.01, height: CGFloat(distance))
        let material = SCNMaterial()
        
        // Full opacity for bones
        let color = source == .primary ?
            UIColor.systemBlue :
            UIColor.systemRed
        
        material.diffuse.contents = color
        boneGeometry.materials = [material]
        
        let boneNode = SCNNode(geometry: boneGeometry)
        
        // Position the bone at the midpoint
        boneNode.position = SCNVector3(midPoint.x, midPoint.y, midPoint.z)
        
        // Calculate the orientation to point from start to end
        let direction = simd_normalize(endPos - startPos)
        let upVector = SIMD3<Float>(0, 1, 0)
        
        // If direction is parallel to up vector, use a different up vector
        let rotationAxis: SIMD3<Float>
        if abs(simd_dot(direction, upVector)) > 0.999 {
            rotationAxis = simd_cross(SIMD3<Float>(1, 0, 0), direction)
        } else {
            rotationAxis = simd_cross(upVector, direction)
        }
        
        let rotationAngle = acos(simd_dot(upVector, direction))
        
        if simd_length(rotationAxis) > 1e-5 {
            let normalizedRotationAxis = simd_normalize(rotationAxis)
            let quaternion = simd_quatf(angle: rotationAngle, axis: normalizedRotationAxis)
            boneNode.simdOrientation = quaternion
        }

        boneNode.opacity = 0.6
        
        parentNode.addChildNode(boneNode)
    }
    
    // Find the lowest point in the skeleton to place on ground
    private func findLowestPoint(_ body: Pose3DBody) -> Float {
        var lowestY = Float.greatestFiniteMagnitude
        
        for (_, joint) in body.joints {
            lowestY = min(lowestY, joint.position.y)
        }
        
        // If no joints found, return 0
        return lowestY != Float.greatestFiniteMagnitude ? lowestY : 0
    }
    
    // Calculate the height of a skeleton (from lowest to highest point)
    private func calculateSkeletonHeight(_ body: Pose3DBody) -> Float {
        var lowest = Float.greatestFiniteMagnitude
        var highest = -Float.greatestFiniteMagnitude
        
        for (_, joint) in body.joints {
            lowest = min(lowest, joint.position.y)
            highest = max(highest, joint.position.y)
        }
        
        return highest - lowest
    }
}
</file>

<file path="MoveInsight/TechniqueComparisonView.swift">
//import SwiftUI
//import AVKit
//
//struct TechniqueComparisonView: View {
//    let technique: BadmintonTechnique
//    let userVideoViewModel: VideoPlayerViewModel
//    let modelVideoViewModel: VideoPlayerViewModel
//    
//    @State private var comparisonMode: ComparisonMode = .sideBySide
//    @State private var selectedReportTab: ReportTab = .overview
//    
//    enum ComparisonMode {
//        case sideBySide
//        case overlay3D
//    }
//    
//    enum ReportTab {
//        case overview
//        case technical
//        case smash
//        case positioning
//    }
//    
//    var body: some View {
//        ZStack {
//            ColorManager.background.ignoresSafeArea()
//            
//            ScrollView {
//                VStack(spacing: 24) {
//                    // Header
//                    Text("\(technique.name) Comparison")
//                        .font(.title2)
//                        .foregroundColor(ColorManager.textPrimary)
//                        .padding(.top, 16)
//                    
//                    // Comparison Mode Selector
//                    Picker("Comparison Mode", selection: $comparisonMode) {
//                        Text("Side by Side").tag(ComparisonMode.sideBySide)
//                        Text("3D Overlay").tag(ComparisonMode.overlay3D)
//                    }
//                    .pickerStyle(SegmentedPickerStyle())
//                    .padding(.horizontal, 20)
//                    
//                    // Comparison content based on selected mode
//                    if comparisonMode == .sideBySide {
//                        sideBySideComparisonView
//                    } else {
//                        overlay3DComparisonView
//                    }
//                    
//                    // Report Tabs
//                    Picker("Report Type", selection: $selectedReportTab) {
//                        Text("Overview").tag(ReportTab.overview)
//                        Text("Technical").tag(ReportTab.technical)
//                        Text("Smash").tag(ReportTab.smash)
//                        Text("Positioning").tag(ReportTab.positioning)
//                    }
//                    .pickerStyle(SegmentedPickerStyle())
//                    .padding(.horizontal, 20)
//                    .padding(.top, 8)
//                    
//                    // Analysis and Feedback based on selected tab
//                    switch selectedReportTab {
//                    case .overview:
//                        overviewAnalysisSection
//                    case .technical:
//                        technicalAnalysisSection
//                    case .smash:
//                        smashAnalysisSection
//                    case .positioning:
//                        positioningAnalysisSection
//                    }
//                }
//                .padding(.bottom, 32)
//            }
//        }
//        .navigationTitle("Technique Analysis")
//        .navigationBarTitleDisplayMode(.inline)
//        .onAppear {
//            // Ensure videos play when the view appears
//            userVideoViewModel.play()
//            modelVideoViewModel.play()
//        }
//        .onDisappear {
//            // Stop videos when view disappears
//            userVideoViewModel.pause()
//            modelVideoViewModel.pause()
//        }
//    }
//    
//    // Side-by-side comparison view
//    private var sideBySideComparisonView: some View {
//        VStack(spacing: 16) {
//            // Videos
//            HStack(spacing: 8) {
//                // Your video
//                VStack {
//                    Text("Your Technique")
//                        .font(.subheadline)
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    VideoPlayerRepresentable(player: userVideoViewModel.player, videoRect: .constant(CGRect()))
//                        .frame(height: 240)
//                        .cornerRadius(12)
//                        .overlay(
//                            RoundedRectangle(cornerRadius: 12)
//                                .stroke(Color.blue, lineWidth: 2)
//                        )
//                }
//                .frame(maxWidth: .infinity)
//                
//                // Model video
//                VStack {
//                    Text("Model Technique")
//                        .font(.subheadline)
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    VideoPlayerRepresentable(player: modelVideoViewModel.player, videoRect: .constant(CGRect()))
//                        .frame(height: 240)
//                        .cornerRadius(12)
//                        .overlay(
//                            RoundedRectangle(cornerRadius: 12)
//                                .stroke(Color.red, lineWidth: 2)
//                        )
//                }
//                .frame(maxWidth: .infinity)
//            }
//            .padding(.horizontal, 8)
//            
//            // Playback controls
//            HStack {
//                Button(action: {
//                    if userVideoViewModel.isPlaying {
//                        userVideoViewModel.pause()
//                        modelVideoViewModel.pause()
//                    } else {
//                        userVideoViewModel.play()
//                        modelVideoViewModel.play()
//                    }
//                }) {
//                    Image(systemName: userVideoViewModel.isPlaying ? "pause.fill" : "play.fill")
//                        .font(.system(size: 24))
//                        .foregroundColor(ColorManager.accentColor)
//                        .frame(width: 44, height: 44)
//                }
//                
//                Button(action: {
//                    userVideoViewModel.restart()
//                    modelVideoViewModel.restart()
//                }) {
//                    Image(systemName: "arrow.clockwise")
//                        .font(.system(size: 20))
//                        .foregroundColor(ColorManager.textPrimary)
//                        .frame(width: 44, height: 44)
//                }
//            }
//            .padding(.bottom, 8)
//        }
//    }
//    
//    // 3D overlay comparison view
//    private var overlay3DComparisonView: some View {
//        VStack(spacing: 16) {
//            // 3D View
//            CombinedVideo3DView(
//                baseViewModel: userVideoViewModel,
//                overlayViewModel: modelVideoViewModel
//            )
//            .frame(height: 400)
//            .cornerRadius(12)
//            .overlay(
//                RoundedRectangle(cornerRadius: 12)
//                    .stroke(ColorManager.accentColor, lineWidth: 2)
//            )
//            .padding(.horizontal, 16)
//            
//            Text("Blue skeleton: Your technique | Red skeleton: Model technique")
//                .font(.caption)
//                .foregroundColor(ColorManager.textSecondary)
//        }
//    }
//    
//    // Original Analysis and feedback section now called "Overview"
//    private var overviewAnalysisSection: some View {
//        VStack(alignment: .leading, spacing: 20) {
//            Text("Analysis & Feedback")
//                .font(.headline)
//                .foregroundColor(ColorManager.textPrimary)
//                .padding(.horizontal, 20)
//            
//            // Technique score
//            HStack {
//                VStack(alignment: .leading, spacing: 4) {
//                    Text("Overall Technique Score")
//                        .font(.subheadline)
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("Based on comparing your form to the model technique")
//                        .font(.caption)
//                        .foregroundColor(ColorManager.textSecondary)
//                }
//                
//                Spacer()
//                
//                ZStack {
//                    Circle()
//                        .stroke(ColorManager.accentColor.opacity(0.3), lineWidth: 8)
//                        .frame(width: 70, height: 70)
//                    
//                    Circle()
//                        .trim(from: 0, to: 0.78) // 78% score
//                        .stroke(ColorManager.accentColor, style: StrokeStyle(lineWidth: 8, lineCap: .round))
//                        .frame(width: 70, height: 70)
//                        .rotationEffect(.degrees(-90))
//                    
//                    Text("78%")
//                        .font(.system(size: 18, weight: .bold))
//                        .foregroundColor(ColorManager.textPrimary)
//                }
//            }
//            .padding(.horizontal, 20)
//            .padding(.vertical, 16)
//            .background(ColorManager.cardBackground.opacity(0.5))
//            .cornerRadius(12)
//            .padding(.horizontal, 20)
//            
//            // Feedback points
//            VStack(alignment: .leading, spacing: 12) {
//                Text("Improvement Areas")
//                    .font(.subheadline)
//                    .foregroundColor(ColorManager.textPrimary)
//                
//                FeedbackItem(
//                    title: "Arm Extension",
//                    description: "Your arm extension is 15% shorter than recommended",
//                    score: 70
//                )
//                
//                FeedbackItem(
//                    title: "Follow Through",
//                    description: "Your follow through motion completes correctly",
//                    score: 95
//                )
//                
//                FeedbackItem(
//                    title: "Racket Angle",
//                    description: "Your racket angle is 10° more vertical than ideal",
//                    score: 75
//                )
//                
//                FeedbackItem(
//                    title: "Timing",
//                    description: "Your timing is well synchronized with the shuttle",
//                    score: 90
//                )
//            }
//            .padding(20)
//            .background(ColorManager.cardBackground.opacity(0.5))
//            .cornerRadius(12)
//            .padding(.horizontal, 20)
//        }
//    }
//    
//    // NEW: Technical Analysis Section
//    private var technicalAnalysisSection: some View {
//        VStack(alignment: .leading, spacing: 20) {
//            Text("Technical Report")
//                .font(.headline)
//                .foregroundColor(ColorManager.textPrimary)
//                .padding(.horizontal, 20)
//            
//            // Technique usage summary
//            VStack(alignment: .leading, spacing: 16) {
//                Text("Technique Usage Summary")
//                    .font(.subheadline)
//                    .foregroundColor(ColorManager.textPrimary)
//                
//                // Column headers
//                HStack {
//                    Text("Technique Type")
//                        .font(.system(size: 14))
//                        .foregroundColor(ColorManager.textSecondary)
//                        .frame(width: 180, alignment: .leading)
//                    
//                    Spacer()
//                    
//                    Text("Uses")
//                        .font(.system(size: 14))
//                        .foregroundColor(ColorManager.textSecondary)
//                        .frame(width: 40, alignment: .center)
//                    
//                    Text("Quality")
//                        .font(.system(size: 14))
//                        .foregroundColor(ColorManager.textSecondary)
//                        .frame(width: 80, alignment: .trailing)
//                }
//                .padding(.bottom, 8)
//                
//                VStack(alignment: .leading, spacing: 12) {
//                    // Smash stats
//                    HStack {
//                        Text("Smash")
//                            .font(.system(size: 16, weight: .medium))
//                            .foregroundColor(ColorManager.textPrimary)
//                            .frame(width: 180, alignment: .leading)
//                        
//                        Spacer()
//                        
//                        Text("10")
//                            .font(.system(size: 16))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .frame(width: 40, alignment: .center)
//                        
//                        Text("40/100")
//                            .font(.system(size: 16))
//                            .foregroundColor(.orange)
//                            .frame(width: 80, alignment: .trailing)
//                    }
//                    
//                    // Forehand High Clear stats
//                    HStack {
//                        Text("Forehand High Clear")
//                            .font(.system(size: 16, weight: .medium))
//                            .foregroundColor(ColorManager.textPrimary)
//                            .frame(width: 180, alignment: .leading)
//                        
//                        Spacer()
//                        
//                        Text("21")
//                            .font(.system(size: 16))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .frame(width: 40, alignment: .center)
//                        
//                        Text("60/100")
//                            .font(.system(size: 16))
//                            .foregroundColor(.yellow)
//                            .frame(width: 80, alignment: .trailing)
//                    }
//                    
//                    // Backhand High Clear stats
//                    HStack {
//                        Text("Backhand High Clear")
//                            .font(.system(size: 16, weight: .medium))
//                            .foregroundColor(ColorManager.textPrimary)
//                            .frame(width: 180, alignment: .leading)
//                        
//                        Spacer()
//                        
//                        Text("12")
//                            .font(.system(size: 16))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .frame(width: 40, alignment: .center)
//                        
//                        Text("92/100")
//                            .font(.system(size: 16))
//                            .foregroundColor(.green)
//                            .frame(width: 80, alignment: .trailing)
//                    }
//                    
//                    // Drop Shot stats
//                    HStack {
//                        Text("Drop Shot")
//                            .font(.system(size: 16, weight: .medium))
//                            .foregroundColor(ColorManager.textPrimary)
//                            .frame(width: 180, alignment: .leading)
//                        
//                        Spacer()
//                        
//                        Text("12")
//                            .font(.system(size: 16))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .frame(width: 40, alignment: .center)
//                        
//                        Text("92/100")
//                            .font(.system(size: 16))
//                            .foregroundColor(.green)
//                            .frame(width: 80, alignment: .trailing)
//                    }
//                    
//                    // Net Shot stats
//                    HStack {
//                        Text("Net Shot")
//                            .font(.system(size: 16, weight: .medium))
//                            .foregroundColor(ColorManager.textPrimary)
//                            .frame(width: 180, alignment: .leading)
//                        
//                        Spacer()
//                        
//                        Text("5")
//                            .font(.system(size: 16))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .frame(width: 40, alignment: .center)
//                        
//                        Text("92/100")
//                            .font(.system(size: 16))
//                            .foregroundColor(.green)
//                            .frame(width: 80, alignment: .trailing)
//                    }
//                }
//            }
//            .padding(20)
//            .background(ColorManager.cardBackground.opacity(0.5))
//            .cornerRadius(12)
//            .padding(.horizontal, 20)
//            
//            // Summary and recommendations
//            VStack(alignment: .leading, spacing: 12) {
//                Text("Summary & Recommendations")
//                    .font(.subheadline)
//                    .foregroundColor(ColorManager.textPrimary)
//                
//                VStack(alignment: .leading, spacing: 8) {
//                    Text("• Only used smash 10 times with 40% success rate. Recommended to increase training frequency.")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("• Forehand high clear success rate is 60% (21 attempts).")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("• Backhand high clear, drop shot, net shot, and push technique scores are above average.")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("• Focus on improving smash power and accuracy through dedicated practice sessions.")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                }
//            }
//            .padding(20)
//            .background(ColorManager.cardBackground.opacity(0.5))
//            .cornerRadius(12)
//            .padding(.horizontal, 20)
//        }
//    }
//    
//    // NEW: Smash Analysis Section
//    private var smashAnalysisSection: some View {
//        VStack(alignment: .leading, spacing: 20) {
//            Text("Smash Technique Analysis")
//                .font(.headline)
//                .foregroundColor(ColorManager.textPrimary)
//                .padding(.horizontal, 20)
//            
//            // Movement sequence chart
//            VStack(alignment: .leading, spacing: 12) {
//                Text("Velocity Profile")
//                    .font(.subheadline)
//                    .foregroundColor(ColorManager.textPrimary)
//                
//                Image("velocity_profile_chart") // Would need to be added to assets
//                    .resizable()
//                    .scaledToFit()
//                    .cornerRadius(8)
//                
//                Divider()
//                
//                // Movement sequence breakdown
//                VStack(alignment: .leading, spacing: 8) {
//                    Text("Optimal Movement Sequence:")
//                        .font(.system(size: 16, weight: .medium))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    HStack(spacing: 0) {
//                        Text("Upper Body")
//                            .font(.system(size: 12))
//                            .foregroundColor(.green)
//                            .padding(.vertical, 4)
//                            .padding(.horizontal, 8)
//                            .background(Color.green.opacity(0.1))
//                            .cornerRadius(4)
//                            .overlay(
//                                RoundedRectangle(cornerRadius: 4)
//                                    .stroke(Color.green, style: StrokeStyle(lineWidth: 1, dash: [3]))
//                            )
//                        
//                        Image(systemName: "arrow.right")
//                            .font(.system(size: 12))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .padding(.horizontal, 4)
//                        
//                        Text("Upper Arm")
//                            .font(.system(size: 12))
//                            .foregroundColor(.green)
//                            .padding(.vertical, 4)
//                            .padding(.horizontal, 8)
//                            .background(Color.green.opacity(0.1))
//                            .cornerRadius(4)
//                            .overlay(
//                                RoundedRectangle(cornerRadius: 4)
//                                    .stroke(Color.green, style: StrokeStyle(lineWidth: 1, dash: [3]))
//                            )
//                        
//                        Image(systemName: "arrow.right")
//                            .font(.system(size: 12))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .padding(.horizontal, 4)
//                        
//                        Text("Forearm")
//                            .font(.system(size: 12))
//                            .foregroundColor(ColorManager.accentColor)
//                            .padding(.vertical, 4)
//                            .padding(.horizontal, 8)
//                            .background(ColorManager.accentColor.opacity(0.1))
//                            .cornerRadius(4)
//                        
//                        Image(systemName: "arrow.right")
//                            .font(.system(size: 12))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .padding(.horizontal, 4)
//                        
//                        Text("Wrist")
//                            .font(.system(size: 12))
//                            .foregroundColor(ColorManager.accentColor)
//                            .padding(.vertical, 4)
//                            .padding(.horizontal, 8)
//                            .background(ColorManager.accentColor.opacity(0.1))
//                            .cornerRadius(4)
//                    }
//                    .padding(.vertical, 8)
//                    
//                    Text("Your Movement Sequence:")
//                        .font(.system(size: 16, weight: .medium))
//                        .foregroundColor(ColorManager.textPrimary)
//                        .padding(.top, 4)
//                    
//                    HStack(spacing: 0) {
//                        Text("Upper Arm")
//                            .font(.system(size: 12))
//                            .foregroundColor(.red)
//                            .padding(.vertical, 4)
//                            .padding(.horizontal, 8)
//                            .background(Color.red.opacity(0.1))
//                            .cornerRadius(4)
//                            .overlay(
//                                RoundedRectangle(cornerRadius: 4)
//                                    .stroke(Color.red, style: StrokeStyle(lineWidth: 1, dash: [3]))
//                            )
//                        
//                        Image(systemName: "arrow.right")
//                            .font(.system(size: 12))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .padding(.horizontal, 4)
//                        
//                        Text("Upper Body")
//                            .font(.system(size: 12))
//                            .foregroundColor(.red)
//                            .padding(.vertical, 4)
//                            .padding(.horizontal, 8)
//                            .background(Color.red.opacity(0.1))
//                            .cornerRadius(4)
//                            .overlay(
//                                RoundedRectangle(cornerRadius: 4)
//                                    .stroke(Color.red, style: StrokeStyle(lineWidth: 1, dash: [3]))
//                            )
//                        
//                        Image(systemName: "arrow.right")
//                            .font(.system(size: 12))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .padding(.horizontal, 4)
//                        
//                        // Missing forearm component - marked in red
//                        Text("Forearm")
//                            .font(.system(size: 12))
//                            .foregroundColor(ColorManager.accentColor)
//                            .padding(.vertical, 4)
//                            .padding(.horizontal, 8)
//                            .background(ColorManager.accentColor.opacity(0.1))
//                            .cornerRadius(4)
//                        
//                        Image(systemName: "arrow.right")
//                            .font(.system(size: 12))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .padding(.horizontal, 4)
//                        
//                        Text("Wrist")
//                            .font(.system(size: 12))
//                            .foregroundColor(ColorManager.accentColor)
//                            .padding(.vertical, 4)
//                            .padding(.horizontal, 8)
//                            .background(ColorManager.accentColor.opacity(0.1))
//                            .cornerRadius(4)
//                    }
//                    .padding(.vertical, 8)
//                }
//            }
//            .padding(20)
//            .background(ColorManager.cardBackground.opacity(0.5))
//            .cornerRadius(12)
//            .padding(.horizontal, 20)
//            
//            // Movement analysis
//            VStack(alignment: .leading, spacing: 12) {
//                Text("Power Generation Analysis")
//                    .font(.subheadline)
//                    .foregroundColor(ColorManager.textPrimary)
//                
//                VStack(alignment: .leading, spacing: 10) {
//                    Text("Your power generation is sequential but missing key component:")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("• Missing forearm rotation phase reduces shuttle velocity by 12-15%")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("• Proper forearm pronation helps transfer energy from elbow to wrist")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("• When elbow rotation is at 150°/s, shuttle peak velocity increases by 12-15%")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("• Focus on adding deliberate forearm rotation before wrist snap for maximum power")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                }
//            }
//            .padding(20)
//            .background(ColorManager.cardBackground.opacity(0.5))
//            .cornerRadius(12)
//            .padding(.horizontal, 20)
//        }
//    }
//    
//    // NEW: Positioning Analysis Section
//    private var positioningAnalysisSection: some View {
//        VStack(alignment: .leading, spacing: 20) {
//            Text("Player-Shuttle Positioning")
//                .font(.headline)
//                .foregroundColor(ColorManager.textPrimary)
//                .padding(.horizontal, 20)
//            
//            // Positioning measurements
//            VStack(alignment: .leading, spacing: 12) {
//                Text("Measurements")
//                    .font(.subheadline)
//                    .foregroundColor(ColorManager.textPrimary)
//                
//                HStack(spacing: 20) {
//                    VStack(alignment: .leading, spacing: 8) {
//                        Text("Your Height:")
//                            .font(.system(size: 15))
//                            .foregroundColor(ColorManager.textSecondary)
//                        
//                        HStack {
//                            Text("2.0m")
//                                .font(.system(size: 18, weight: .bold))
//                                .foregroundColor(.red)
//                            
//                            Image(systemName: "arrow.down")
//                                .font(.system(size: 12))
//                                .foregroundColor(.red)
//                        }
//                        
//                        Text("Recommended:")
//                            .font(.system(size: 15))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .padding(.top, 4)
//                        
//                        Text("2.1m")
//                            .font(.system(size: 18, weight: .bold))
//                            .foregroundColor(.green)
//                    }
//                    
//                    Divider()
//                        .frame(width: 1, height: 100)
//                        .background(ColorManager.textSecondary.opacity(0.3))
//                    
//                    VStack(alignment: .leading, spacing: 8) {
//                        Text("Your Horizontal Distance:")
//                            .font(.system(size: 15))
//                            .foregroundColor(ColorManager.textSecondary)
//                        
//                        HStack {
//                            Text("60cm")
//                                .font(.system(size: 18, weight: .bold))
//                                .foregroundColor(.red)
//                            
//                            Image(systemName: "arrow.right")
//                                .font(.system(size: 12))
//                                .foregroundColor(.red)
//                        }
//                        
//                        Text("Recommended:")
//                            .font(.system(size: 15))
//                            .foregroundColor(ColorManager.textSecondary)
//                            .padding(.top, 4)
//                        
//                        Text("40-50cm")
//                            .font(.system(size: 18, weight: .bold))
//                            .foregroundColor(.green)
//                    }
//                }
//                .padding(.vertical, 8)
//                
//                // Positioning diagram
//                Image("player_shuttle_distance")
//                    .resizable()
//                    .scaledToFit()
//                    .cornerRadius(8)
//            }
//            .padding(20)
//            .background(ColorManager.cardBackground.opacity(0.5))
//            .cornerRadius(12)
//            .padding(.horizontal, 20)
//            
//            // Positioning analysis and recommendations
//            VStack(alignment: .leading, spacing: 12) {
//                Text("Analysis & Improvement Suggestions")
//                    .font(.subheadline)
//                    .foregroundColor(ColorManager.textPrimary)
//                
//                VStack(alignment: .leading, spacing: 12) {
//                    Text("Impact of current positioning:")
//                        .font(.system(size: 15, weight: .medium))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("• Hitting point too low and forward prevents full arm extension and power generation")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("• Shuttle contact angle becomes too flat, reducing control and shot quality")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("• Wrist and shoulder strain increases due to improper power generation mechanics")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("Recommended adjustments:")
//                        .font(.system(size: 15, weight: .medium))
//                        .foregroundColor(ColorManager.textPrimary)
//                        .padding(.top, 8)
//                    
//                    Text("• Adjust hitting timing to keep contact point above your body")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("• Allow natural wrist extension position for optimal power transfer")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                    
//                    Text("• Decrease horizontal distance to 40-50cm for better leverage and control")
//                        .font(.system(size: 15))
//                        .foregroundColor(ColorManager.textPrimary)
//                }
//            }
//            .padding(20)
//            .background(ColorManager.cardBackground.opacity(0.5))
//            .cornerRadius(12)
//            .padding(.horizontal, 20)
//        }
//    }
//}
//
//// Feedback item component
//struct FeedbackItem: View {
//    let title: String
//    let description: String
//    let score: Int
//    
//    var body: some View {
//        HStack(alignment: .center, spacing: 16) {
//            // Score circle
//            ZStack {
//                Circle()
//                    .fill(scoreColor.opacity(0.2))
//                    .frame(width: 40, height: 40)
//                
//                Text("\(score)%")
//                    .font(.system(size: 12, weight: .bold))
//                    .foregroundColor(scoreColor)
//            }
//            
//            // Feedback text
//            VStack(alignment: .leading, spacing: 4) {
//                Text(title)
//                    .font(.subheadline)
//                    .foregroundColor(ColorManager.textPrimary)
//                
//                Text(description)
//                    .font(.caption)
//                    .foregroundColor(ColorManager.textSecondary)
//            }
//        }
//    }
//    
//    // Color based on the score
//    private var scoreColor: Color {
//        if score >= 90 {
//            return .green
//        } else if score >= 75 {
//            return .yellow
//        } else if score >= 60 {
//            return .orange
//        } else {
//            return .red
//        }
//    }
//}

import SwiftUI
import AVKit
import Combine

struct TechniqueComparisonView: View {
    let technique: BadmintonTechnique
    let userVideoViewModel: VideoPlayerViewModel
    let modelVideoViewModel: VideoPlayerViewModel
    
    @State private var comparisonMode: ComparisonMode = .sideBySide
    @State private var selectedReportTab: ReportTab = .overview
    
    // Analysis state
    @State private var analysisResult: ComparisonResult?
    @State private var isAnalyzing = false
    @State private var analysisError: String? = nil
    @State private var cancellables = Set<AnyCancellable>()
    
    enum ComparisonMode {
        case sideBySide
        case overlay3D
    }
    
    enum ReportTab {
        case overview
        case technical
    }
    
    var body: some View {
        ZStack {
            ColorManager.background.ignoresSafeArea()
            
            ScrollView {
                VStack(spacing: 24) {
                    // Header
                    Text("\(technique.name) Analysis")
                        .font(.title2)
                        .foregroundColor(ColorManager.textPrimary)
                        .padding(.top, 16)
                    
                    // Comparison Mode Selector
                    Picker("Comparison Mode", selection: $comparisonMode) {
                        Text("Side by Side").tag(ComparisonMode.sideBySide)
                        Text("3D Overlay").tag(ComparisonMode.overlay3D)
                    }
                    .pickerStyle(SegmentedPickerStyle())
                    .padding(.horizontal, 20)
                    
                    // Comparison content based on selected mode
                    if comparisonMode == .sideBySide {
                        sideBySideComparisonView
                    } else {
                        overlay3DComparisonView
                    }
                    
                    // Report Tabs
                    Picker("Report Type", selection: $selectedReportTab) {
                        Text("Overview").tag(ReportTab.overview)
                        Text("Technical").tag(ReportTab.technical)
                    }
                    .pickerStyle(SegmentedPickerStyle())
                    .padding(.horizontal, 20)
                    .padding(.top, 8)
                    
                    // Analysis and Feedback based on selected tab
                    switch selectedReportTab {
                    case .overview:
                        overviewAnalysisSection
                    case .technical:
                        technicalAnalysisSection
                    }
                }
                .padding(.bottom, 32)
            }
        }
        .navigationTitle("Technique Analysis")
        .navigationBarTitleDisplayMode(.inline)
        .onAppear {
            // Ensure videos play when the view appears
            userVideoViewModel.play()
            modelVideoViewModel.play()
            
            // Perform analysis after a short delay to ensure videos are loaded
            DispatchQueue.main.asyncAfter(deadline: .now() + 1.5) {
                performAnalysis()
            }
        }
        .onDisappear {
            // Stop videos when view disappears
            userVideoViewModel.pause()
            modelVideoViewModel.pause()
            
            // Cancel any pending analysis
            cancellables.forEach { $0.cancel() }
            cancellables.removeAll()
        }
    }
    
    // Side-by-side comparison view
    private var sideBySideComparisonView: some View {
        VStack(spacing: 16) {
            // Videos
            HStack(spacing: 8) {
                // Your video
                VStack {
                    Text("Your Technique")
                        .font(.subheadline)
                        .foregroundColor(ColorManager.textPrimary)
                    
                    VideoPlayerRepresentable(player: userVideoViewModel.player, videoRect: .constant(CGRect()))
                        .frame(height: 240)
                        .cornerRadius(12)
                        .overlay(
                            RoundedRectangle(cornerRadius: 12)
                                .stroke(Color.blue, lineWidth: 2)
                        )
                }
                .frame(maxWidth: .infinity)
                
                // Model video
                VStack {
                    Text("Model Technique")
                        .font(.subheadline)
                        .foregroundColor(ColorManager.textPrimary)
                    
                    VideoPlayerRepresentable(player: modelVideoViewModel.player, videoRect: .constant(CGRect()))
                        .frame(height: 240)
                        .cornerRadius(12)
                        .overlay(
                            RoundedRectangle(cornerRadius: 12)
                                .stroke(Color.red, lineWidth: 2)
                        )
                }
                .frame(maxWidth: .infinity)
            }
            .padding(.horizontal, 8)
            
            // Playback controls
            HStack {
                Button(action: {
                    if userVideoViewModel.isPlaying {
                        userVideoViewModel.pause()
                        modelVideoViewModel.pause()
                    } else {
                        userVideoViewModel.play()
                        modelVideoViewModel.play()
                    }
                }) {
                    Image(systemName: userVideoViewModel.isPlaying ? "pause.fill" : "play.fill")
                        .font(.system(size: 24))
                        .foregroundColor(ColorManager.accentColor)
                        .frame(width: 44, height: 44)
                }
                
                Button(action: {
                    userVideoViewModel.restart()
                    modelVideoViewModel.restart()
                }) {
                    Image(systemName: "arrow.clockwise")
                        .font(.system(size: 20))
                        .foregroundColor(ColorManager.textPrimary)
                        .frame(width: 44, height: 44)
                }
            }
            .padding(.bottom, 8)
        }
    }
    
    // 3D overlay comparison view
    private var overlay3DComparisonView: some View {
        VStack(spacing: 16) {
            // 3D View
            CombinedVideo3DView(
                baseViewModel: userVideoViewModel,
                overlayViewModel: modelVideoViewModel
            )
            .frame(height: 400)
            .cornerRadius(12)
            .overlay(
                RoundedRectangle(cornerRadius: 12)
                    .stroke(ColorManager.accentColor, lineWidth: 2)
            )
            .padding(.horizontal, 16)
            
            Text("Blue skeleton: Your technique | Red skeleton: Model technique")
                .font(.caption)
                .foregroundColor(ColorManager.textSecondary)
        }
    }
    
    // Overview Analysis Section - focused on server results
    private var overviewAnalysisSection: some View {
        VStack(alignment: .leading, spacing: 20) {
            Text("Analysis & Feedback")
                .font(.headline)
                .foregroundColor(ColorManager.textPrimary)
                .padding(.horizontal, 20)
            
            if isAnalyzing {
                // Loading state
                HStack {
                    Spacer()
                    VStack(spacing: 16) {
                        ProgressView()
                            .progressViewStyle(CircularProgressViewStyle(tint: ColorManager.accentColor))
                            .scaleEffect(1.5)
                        
                        Text("Analyzing your technique...")
                            .font(.subheadline)
                            .foregroundColor(ColorManager.textPrimary)
                        
                        Text("Comparing with model performance")
                            .font(.caption)
                            .foregroundColor(ColorManager.textSecondary)
                    }
                    .padding(.vertical, 40)
                    Spacer()
                }
            } else if let error = analysisError {
                // Error state
                VStack(alignment: .center, spacing: 16) {
                    Image(systemName: "exclamationmark.triangle.fill")
                        .font(.system(size: 40))
                        .foregroundColor(.orange)
                    
                    Text("Analysis Error")
                        .font(.headline)
                        .foregroundColor(ColorManager.textPrimary)
                    
                    Text(error)
                        .font(.subheadline)
                        .foregroundColor(ColorManager.textSecondary)
                        .multilineTextAlignment(.center)
                    
                    Button(action: {
                        performAnalysis()
                    }) {
                        Text("Retry Analysis")
                            .font(.headline)
                            .foregroundColor(.white)
                            .padding()
                            .background(ColorManager.accentColor)
                            .cornerRadius(8)
                    }
                    .padding(.top, 8)
                }
                .frame(maxWidth: .infinity)
                .padding(.vertical, 30)
                .padding(.horizontal, 20)
                .background(ColorManager.cardBackground.opacity(0.5))
                .cornerRadius(12)
                .padding(.horizontal, 20)
            } else if let result = analysisResult {
                // Success state - show technique score
                HStack {
                    VStack(alignment: .leading, spacing: 4) {
                        Text("Overall Technique Score")
                            .font(.subheadline)
                            .foregroundColor(ColorManager.textPrimary)
                        
                        Text("Based on comparing your form to the model technique")
                            .font(.caption)
                            .foregroundColor(ColorManager.textSecondary)
                    }
                    
                    Spacer()
                    
                    ZStack {
                        Circle()
                            .stroke(ColorManager.accentColor.opacity(0.3), lineWidth: 8)
                            .frame(width: 70, height: 70)
                        
                        Circle()
                            .trim(from: 0, to: CGFloat(result.userScore / 100.0))
                            .stroke(ColorManager.accentColor, style: StrokeStyle(lineWidth: 8, lineCap: .round))
                            .frame(width: 70, height: 70)
                            .rotationEffect(.degrees(-90))
                        
                        Text("\(Int(result.userScore))%")
                            .font(.system(size: 18, weight: .bold))
                            .foregroundColor(ColorManager.textPrimary)
                    }
                }
                .padding(.horizontal, 20)
                .padding(.vertical, 16)
                .background(ColorManager.cardBackground.opacity(0.5))
                .cornerRadius(12)
                .padding(.horizontal, 20)
                
                // Feedback points based on the analysis
                VStack(alignment: .leading, spacing: 12) {
                    Text("Technique Analysis")
                        .font(.subheadline)
                        .foregroundColor(ColorManager.textPrimary)
                    
                    ForEach(Array(result.userDetails.keys.sorted()), id: \.self) { key in
                        let passed = result.userDetails[key] ?? false
                        let displayName = formatRuleName(key)
                        let description = getDescription(for: key, passed: passed)
                        
                        FeedbackItem(
                            title: displayName,
                            description: description,
                            score: passed ? 95 : 65
                        )
                    }
                }
                .padding(20)
                .background(ColorManager.cardBackground.opacity(0.5))
                .cornerRadius(12)
                .padding(.horizontal, 20)
            } else {
                // Initial state - no analysis yet
                Button(action: {
                    performAnalysis()
                }) {
                    HStack {
                        Image(systemName: "waveform.path")
                            .font(.system(size: 20))
                        Text("Analyze Technique")
                            .font(.headline)
                    }
                    .frame(maxWidth: .infinity)
                    .padding()
                    .background(ColorManager.accentColor)
                    .foregroundColor(.white)
                    .cornerRadius(12)
                }
                .padding(.horizontal, 20)
            }
        }
    }
    
    // Technical Analysis Section
    private var technicalAnalysisSection: some View {
        VStack(alignment: .leading, spacing: 20) {
            Text("Technical Report")
                .font(.headline)
                .foregroundColor(ColorManager.textPrimary)
                .padding(.horizontal, 20)
            
            if let result = analysisResult {
                // Display comparison details
                VStack(alignment: .leading, spacing: 16) {
                    Text("Comparison with Model")
                        .font(.subheadline)
                        .foregroundColor(ColorManager.textPrimary)
                    
                    HStack(spacing: 20) {
                        // Your score
                        VStack(alignment: .center, spacing: 8) {
                            Text("Your Score")
                                .font(.caption)
                                .foregroundColor(ColorManager.textSecondary)
                            
                            ZStack {
                                Circle()
                                    .stroke(Color.blue.opacity(0.3), lineWidth: 8)
                                    .frame(width: 70, height: 70)
                                
                                Circle()
                                    .trim(from: 0, to: CGFloat(result.userScore / 100.0))
                                    .stroke(Color.blue, style: StrokeStyle(lineWidth: 8, lineCap: .round))
                                    .frame(width: 70, height: 70)
                                    .rotationEffect(.degrees(-90))
                                
                                Text("\(Int(result.userScore))%")
                                    .font(.system(size: 18, weight: .bold))
                                    .foregroundColor(ColorManager.textPrimary)
                            }
                        }
                        .frame(maxWidth: .infinity)
                        
                        // Model score
                        VStack(alignment: .center, spacing: 8) {
                            Text("Model Score")
                                .font(.caption)
                                .foregroundColor(ColorManager.textSecondary)
                            
                            ZStack {
                                Circle()
                                    .stroke(Color.red.opacity(0.3), lineWidth: 8)
                                    .frame(width: 70, height: 70)
                                
                                Circle()
                                    .trim(from: 0, to: CGFloat(result.referenceScore / 100.0))
                                    .stroke(Color.red, style: StrokeStyle(lineWidth: 8, lineCap: .round))
                                    .frame(width: 70, height: 70)
                                    .rotationEffect(.degrees(-90))
                                
                                Text("\(Int(result.referenceScore))%")
                                    .font(.system(size: 18, weight: .bold))
                                    .foregroundColor(ColorManager.textPrimary)
                            }
                        }
                        .frame(maxWidth: .infinity)
                    }
                    .padding(.top, 10)
                    
                    Divider()
                        .padding(.vertical, 10)
                    
                    // Similarity analysis
                    Text("Technical Elements")
                        .font(.subheadline)
                        .foregroundColor(ColorManager.textPrimary)
                    
                    // Column headers
                    HStack {
                        Text("Technique Element")
                            .font(.system(size: 14))
                            .foregroundColor(ColorManager.textSecondary)
                            .frame(width: 180, alignment: .leading)
                        
                        Spacer()
                        
                        Text("Your Performance")
                            .font(.system(size: 14))
                            .foregroundColor(ColorManager.textSecondary)
                            .frame(width: 140, alignment: .trailing)
                    }
                    .padding(.bottom, 8)
                    
                    // List of technique elements
                    ForEach(Array(result.userDetails.keys.sorted()), id: \.self) { key in
                        let userPassed = result.userDetails[key] ?? false
                        let referencePassed = result.referenceDetails[key] ?? false
                        let similar = result.similarity[key] ?? false
                        
                        HStack {
                            Text(formatRuleName(key))
                                .font(.system(size: 16, weight: .medium))
                                .foregroundColor(ColorManager.textPrimary)
                                .frame(width: 180, alignment: .leading)
                                .lineLimit(1)
                            
                            Spacer()
                            
                            HStack(spacing: 8) {
                                Image(systemName: userPassed ? "checkmark.circle.fill" : "xmark.circle.fill")
                                    .foregroundColor(userPassed ? .green : .orange)
                                
                                Text(userPassed ? "Correct" : "Needs Work")
                                    .font(.system(size: 16))
                                    .foregroundColor(userPassed ? .green : .orange)
                            }
                            .frame(width: 140, alignment: .trailing)
                        }
                        .padding(.vertical, 8)
                        .padding(.horizontal, 4)
                        .background(similar ? Color.clear : ColorManager.cardBackground.opacity(0.3))
                        .cornerRadius(8)
                    }
                }
                .padding(20)
                .background(ColorManager.cardBackground.opacity(0.5))
                .cornerRadius(12)
                .padding(.horizontal, 20)
                
                // Improvement suggestions
                VStack(alignment: .leading, spacing: 12) {
                    Text("Improvement Areas")
                        .font(.subheadline)
                        .foregroundColor(ColorManager.textPrimary)
                    
                    let improvementAreas = result.userDetails.filter { !$0.value }.keys.sorted()
                    
                    if improvementAreas.isEmpty {
                        Text("All technical elements performed correctly! Great job!")
                            .font(.system(size: 15))
                            .foregroundColor(.green)
                            .padding(.vertical, 8)
                    } else {
                        ForEach(improvementAreas, id: \.self) { key in
                            Text("• \(getDescription(for: key, passed: false))")
                                .font(.system(size: 15))
                                .foregroundColor(ColorManager.textPrimary)
                                .padding(.vertical, 4)
                        }
                    }
                }
                .padding(20)
                .background(ColorManager.cardBackground.opacity(0.5))
                .cornerRadius(12)
                .padding(.horizontal, 20)
            } else if isAnalyzing {
                // Loading state for technical tab
                HStack {
                    Spacer()
                    ProgressView()
                        .progressViewStyle(CircularProgressViewStyle(tint: ColorManager.accentColor))
                    Spacer()
                }
                .padding(.vertical, 50)
            } else {
                // Prompt to analyze
                HStack {
                    Spacer()
                    VStack(spacing: 16) {
                        Image(systemName: "arrow.up")
                            .font(.system(size: 24))
                            .foregroundColor(ColorManager.textSecondary)
                        
                        Text("Please analyze your technique first")
                            .font(.subheadline)
                            .foregroundColor(ColorManager.textSecondary)
                    }
                    Spacer()
                }
                .padding(.vertical, 50)
            }
        }
    }
    
    // MARK: - Analysis Service Methods
    
    // Perform the analysis with server
    // Perform the analysis with server
    private func performAnalysis() {
        // Clear any previous results
        analysisResult = nil
        analysisError = nil
        isAnalyzing = true
        
        // Clear any previously accumulated poses
        userVideoViewModel.clearAccumulatedPoses()
        modelVideoViewModel.clearAccumulatedPoses()
        
        // Restart both videos from the beginning
        userVideoViewModel.restart()
        modelVideoViewModel.restart()
        
        // Give the videos time to play and accumulate frames
        DispatchQueue.main.asyncAfter(deadline: .now() + 3.0) {
            // Pause videos after collecting frames
            self.userVideoViewModel.pause()
            self.modelVideoViewModel.pause()
            
            // Now perform the analysis with collected frames
            let service = TechniqueAnalysisService()
            service.compareTechniques(
                userViewModel: self.userVideoViewModel,
                modelViewModel: self.modelVideoViewModel
            )
            .sink(
                receiveCompletion: { completion in
                    self.isAnalyzing = false
                    
                    if case let .failure(error) = completion {
                        self.analysisError = error.localizedDescription
                        print("Analysis error: \(error.localizedDescription)")
                    }
                    
                    // Restart videos for viewing
                    self.userVideoViewModel.restart()
                    self.modelVideoViewModel.restart()
                },
                receiveValue: { result in
                    self.analysisResult = result
                    print("Analysis complete: User score \(result.userScore)%, Reference score \(result.referenceScore)%")
                }
            )
            .store(in: &self.cancellables)
        }
    }
    
    // Helper functions to format rule names and descriptions
    private func formatRuleName(_ rule: String) -> String {
        let names: [String: String] = [
            "shoulder_abduction": "Shoulder Position",
            "elbow_flexion": "Elbow Flexion",
            "elbow_lower": "Elbow Height",
            "foot_direction_aligned": "Foot Alignment",
            "proximal_to_distal_sequence": "Power Sequence",
            "hip_forward_shift": "Hip Forward Movement",
            "trunk_rotation_completed": "Trunk Rotation"
        ]
        return names[rule] ?? rule.replacingOccurrences(of: "_", with: " ").capitalized
    }
    
    private func getDescription(for rule: String, passed: Bool) -> String {
        let descriptions: [String: (pass: String, fail: String)] = [
            "shoulder_abduction": (
                pass: "Great shoulder abduction angle between 60-90°",
                fail: "Improve shoulder abduction angle (aim for 60-90°)"
            ),
            "elbow_flexion": (
                pass: "Good elbow flexion, less than 90°",
                fail: "Increase elbow flexion, aim for angle less than 90°"
            ),
            "elbow_lower": (
                pass: "Correct elbow position, racket arm lower than non-racket arm",
                fail: "Lower your racket arm elbow below your non-racket arm"
            ),
            "foot_direction_aligned": (
                pass: "Proper foot alignment provides good stability",
                fail: "Align your feet in the same direction for better balance"
            ),
            "proximal_to_distal_sequence": (
                pass: "Excellent power generation sequence",
                fail: "Improve your swing sequence: shoulder→elbow→wrist"
            ),
            "hip_forward_shift": (
                pass: "Good hip forward movement for power transfer",
                fail: "Shift your hips forward during the swing for more power"
            ),
            "trunk_rotation_completed": (
                pass: "Full trunk rotation generates maximum power",
                fail: "Complete your trunk rotation for improved power generation"
            )
        ]
        
        if let description = descriptions[rule] {
            return passed ? description.pass : description.fail
        }
        return passed ? "Technique element performed correctly" : "This technique element needs improvement"
    }
}

// MARK: - Supporting Structures

// Feedback item component
struct FeedbackItem: View {
    let title: String
    let description: String
    let score: Int
    
    var body: some View {
        HStack(alignment: .center, spacing: 16) {
            // Score circle
            ZStack {
                Circle()
                    .fill(scoreColor.opacity(0.2))
                    .frame(width: 40, height: 40)
                
                Text("\(score)%")
                    .font(.system(size: 12, weight: .bold))
                    .foregroundColor(scoreColor)
            }
            
            // Feedback text
            VStack(alignment: .leading, spacing: 4) {
                Text(title)
                    .font(.subheadline)
                    .foregroundColor(ColorManager.textPrimary)
                
                Text(description)
                    .font(.caption)
                    .foregroundColor(ColorManager.textSecondary)
            }
        }
    }
    
    // Color based on the score
    private var scoreColor: Color {
        if score >= 90 {
            return .green
        } else if score >= 75 {
            return .yellow
        } else if score >= 60 {
            return .orange
        } else {
            return .red
        }
    }
}

// Data structure for results
struct ComparisonResult: Codable {
    let userScore: Double
    let referenceScore: Double
    let similarity: [String: Bool]
    let userDetails: [String: Bool]
    let referenceDetails: [String: Bool]
    
    enum CodingKeys: String, CodingKey {
        case userScore = "user_score"
        case referenceScore = "reference_score"
        case similarity
        case userDetails = "user_details"
        case referenceDetails = "reference_details"
    }
}
</file>

<file path="MoveInsight/TechniqueDetailView.swift">
import SwiftUI
import AVKit
import Combine

struct TechniqueDetailView: View {
    let technique: BadmintonTechnique
    
    // State to track the user's current progress
    @State private var uploadedVideoURL: URL?
    @State private var videoVM: VideoPlayerViewModel?
    @State private var showUploadOptions = false
    @State private var isVideoBeingProcessed = false
    @State private var isForComparison = false // Track if this is for comparison
    
    // Cancellables for video ready listener
    @State private var cancellables = Set<AnyCancellable>()
    
    // Added state for navigation to comparison view
    @State private var navigateToComparison = false
    @State private var modelVM: VideoPlayerViewModel?
    @State private var secondVideoVM: VideoPlayerViewModel?
    
    var body: some View {
        ZStack {
            ColorManager.background.ignoresSafeArea()
            
            ScrollView {
                VStack(spacing: 24) {
                    // Technique header
                    VStack(spacing: 12) {
                        ZStack {
                            Circle()
                                .fill(ColorManager.accentColor.opacity(0.2))
                                .frame(width: 80, height: 80)
                            
                            Image(systemName: technique.iconName)
                                .font(.system(size: 36))
                                .foregroundColor(ColorManager.accentColor)
                        }
                        
                        Text(technique.name)
                            .font(.title)
                            .foregroundColor(ColorManager.textPrimary)
                            .multilineTextAlignment(.center)
                        
                        Text(technique.description)
                            .font(.body)
                            .foregroundColor(ColorManager.textSecondary)
                            .multilineTextAlignment(.center)
                            .padding(.horizontal, 24)
                    }
                    .padding(.top, 24)
                    
                    // Show loading indicator while video is processing
                    if isVideoBeingProcessed {
                        VStack(spacing: 16) {
                            ProgressView()
                                .progressViewStyle(CircularProgressViewStyle(tint: ColorManager.accentColor))
                                .scaleEffect(1.5)
                            
                            Text("Processing video...")
                                .foregroundColor(ColorManager.textPrimary)
                        }
                        .frame(height: 300)
                        .frame(maxWidth: .infinity)
                        .background(Color.black.opacity(0.05))
                        .cornerRadius(12)
                        .padding(.horizontal)
                    }
                    // Video preview if uploaded and ready
                    else if let videoVM = videoVM, videoVM.isVideoReady {
                        VStack(spacing: 12) {
                            Text("Your Video")
                                .font(.headline)
                                .foregroundColor(ColorManager.textPrimary)
                            
                            VideoPlayerRepresentable(player: videoVM.player, videoRect: .constant(CGRect()))
                                .frame(height: 300)
                                .cornerRadius(12)
                                .onAppear {
                                    videoVM.play()
                                }
                                .onDisappear {
                                    videoVM.pause()
                                }
                        }
                        .padding(.horizontal)
                        
                        // Options after video is processed and ready
                        VStack(spacing: 20) {
                            Text("What would you like to do next?")
                                .font(.title3)
                                .fontWeight(.bold)
                                .foregroundColor(ColorManager.textPrimary)
                                .padding(.top, 20)
                            
                            HStack(spacing: 16) {
                                Button(action: {
                                    // Navigate to upload a second video for comparison
                                    isForComparison = true
                                    openTechniqueVideoUpload(forComparison: true)
                                }) {
                                    VStack(spacing: 12) {
                                        Image(systemName: "plus.viewfinder")
                                            .font(.system(size: 30))
                                        Text("Upload Second Video")
                                            .font(.headline)
                                            .multilineTextAlignment(.center)
                                    }
                                    .frame(maxWidth: .infinity)
                                    .padding(.vertical, 20)
                                    .background(ColorManager.cardBackground)
                                    .foregroundColor(ColorManager.textPrimary)
                                    .cornerRadius(12)
                                }
                                
                                Button(action: {
                                    // Compare with model video
                                    compareWithModelVideo()
                                }) {
                                    VStack(spacing: 12) {
                                        Image(systemName: "person.fill.viewfinder")
                                            .font(.system(size: 30))
                                        Text("Compare with Model")
                                            .font(.headline)
                                            .multilineTextAlignment(.center)
                                    }
                                    .frame(maxWidth: .infinity)
                                    .padding(.vertical, 20)
                                    .background(ColorManager.accentColor)
                                    .foregroundColor(.white)
                                    .cornerRadius(12)
                                }
                                .disabled(!technique.hasModelVideo)
                                .opacity(technique.hasModelVideo ? 1.0 : 0.5)
                            }
                            .padding(.horizontal)
                        }
                        .padding(.horizontal)
                    } else {
                        // Show upload button if no video is uploaded yet
                        UploadButton(title: "Upload Your \(technique.name) Video", iconName: "video.badge.plus") {
                            isForComparison = false
                            openTechniqueVideoUpload(forComparison: false)
                        }
                        .padding(.top, 20)
                    }
                    
                    // Tips section
                    VStack(alignment: .leading, spacing: 16) {
                        Text("Key Points for \(technique.name)")
                            .font(.headline)
                            .foregroundColor(ColorManager.textPrimary)
                        
                        KeyPointRow(icon: "figure.play", text: "Start with proper stance, feet shoulder-width apart")
                        KeyPointRow(icon: "hand.raised", text: "Grip the racket with a relaxed, comfortable hold")
                        KeyPointRow(icon: "arrow.up.and.down.and.arrow.left.and.right", text: "Maintain balance throughout the motion")
                        KeyPointRow(icon: "eye", text: "Keep your eye on the shuttle at all times")
                        KeyPointRow(icon: "figure.walk", text: "Follow through with your swing for better control")
                    }
                    .padding()
                    .background(
                        RoundedRectangle(cornerRadius: 12)
                            .fill(ColorManager.cardBackground)
                    )
                    .padding(.horizontal)
                }
                .padding(.bottom, 32)
            }
        }
        .navigationTitle(technique.name)
        .navigationBarTitleDisplayMode(.inline)
        .sheet(isPresented: $showUploadOptions) {
            TechniqueVideoUploadView(technique: technique, isComparison: isForComparison) { videoURL in
                if let url = videoURL {
                    if isForComparison {
                        // Handle second video upload - go straight to comparison
                        processSecondVideo(url)
                    } else {
                        // Handle first video upload
                        self.uploadedVideoURL = url
                        processUploadedVideo(url)
                    }
                    
                    // We'll dismiss the sheet after video is fully processed
                    DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                        showUploadOptions = false
                    }
                }
            }
        }
        .onChange(of: showUploadOptions) { isShowing in
            if !isShowing && isVideoBeingProcessed {
                print("Upload sheet dismissed, continuing to monitor video processing state")
            }
        }
        .background(
            // Hidden navigation link for comparison view
            NavigationLink(destination:
                        Group {
                            if isForComparison, let userVM = videoVM, let secondVM = secondVideoVM {
                                // Two user videos
                                TechniqueComparisonView(
                                    technique: technique,
                                    userVideoViewModel: userVM,
                                    modelVideoViewModel: secondVM
                                )
                            } else if let userVM = videoVM, let modelVM = modelVM {
                                // User video vs model
                                TechniqueComparisonView(
                                    technique: technique,
                                    userVideoViewModel: userVM,
                                    modelVideoViewModel: modelVM
                                )
                            } else {
                                Text("Preparing comparison...")
                            }
                        },
                       isActive: $navigateToComparison) {
                EmptyView()
            }
        )
    }
    
    // Function to open the video upload view
    private func openTechniqueVideoUpload(forComparison: Bool) {
        self.showUploadOptions = true
    }
    
    // Process the uploaded video (first video)
    private func processUploadedVideo(_ url: URL) {
        // Indicate that processing has started
        isVideoBeingProcessed = true
        
        // Create the video view model and begin processing
        videoVM = VideoPlayerViewModel(
            videoURL: url,
            videoSource: .primary
        )
        
        // Set up a publisher to listen for isVideoReady changes
        guard let videoVM = videoVM else { return }
        
        videoVM.$isVideoReady
            .dropFirst() // Skip initial false value
            .sink { isReady in
                if isReady {
                    print("Video is now ready - updating UI")
                    self.isVideoBeingProcessed = false
                }
            }
            .store(in: &cancellables)
        
        print("Started video processing - waiting for it to be ready")
    }
    
    // Process the second uploaded video for comparison
    private func processSecondVideo(_ url: URL) {
        // Create model for second video
        let secondVM = VideoPlayerViewModel(
            videoURL: url,
            videoSource: .secondary
        )
        
        self.secondVideoVM = secondVM
        
        // Wait for the second video to be ready
        secondVM.$isVideoReady
            .dropFirst()
            .sink { isReady in
                if isReady && self.videoVM?.isVideoReady == true {
                    // Navigate to comparison view when both videos are ready
                    DispatchQueue.main.async {
                        self.navigateToComparison = true
                    }
                }
            }
            .store(in: &cancellables)
    }
    
    // Function to compare with model video
    private func compareWithModelVideo() {
        // Use ModelVideoLoader to get the model video
        let modelLoader = ModelVideoLoader.shared
        
        // Get model video for this specific technique
        guard let newModelVM = modelLoader.createModelVideoViewModel(for: technique.name) else {
            // Show an alert to the user
            let alert = UIAlertController(
                title: "Model Video Not Available",
                message: "The model video for \(technique.name) could not be loaded. Please try again later.",
                preferredStyle: .alert
            )
            alert.addAction(UIAlertAction(title: "OK", style: .default))
            
            DispatchQueue.main.async {
                if let windowScene = UIApplication.shared.connectedScenes.first as? UIWindowScene,
                   let rootViewController = windowScene.windows.first?.rootViewController {
                    rootViewController.present(alert, animated: true)
                }
            }
            return
        }
        
        // Store the model view model and navigate
        self.isForComparison = false // Not using second user video
        self.modelVM = newModelVM
        self.navigateToComparison = true
    }
}

// Helper View for Key Points
struct KeyPointRow: View {
    let icon: String
    let text: String
    
    var body: some View {
        HStack(spacing: 12) {
            Image(systemName: icon)
                .font(.system(size: 18))
                .foregroundColor(ColorManager.accentColor)
                .frame(width: 24, height: 24)
            
            Text(text)
                .font(.subheadline)
                .foregroundColor(ColorManager.textPrimary)
            
            Spacer()
        }
    }
}
</file>

<file path="MoveInsight/TechniquesListView.swift">
import SwiftUI
import AVKit

// Define a structure for badminton techniques
struct BadmintonTechnique: Identifiable {
    let id = UUID()
    let name: String
    let description: String
    let iconName: String
    
    // Flag to indicate if we have a model video for this technique
    let hasModelVideo: Bool
}

struct TechniquesListView: View {
    // List of all badminton techniques
    let techniques = [
        BadmintonTechnique(
            name: "Backhand Clear",
            description: "A clear shot played with the back of the hand facing forward.",
            iconName: "arrow.left.arrow.right",
            hasModelVideo: ModelVideoLoader.shared.hasModelVideo(for: "Backhand Clear")
        ),
        BadmintonTechnique(
            name: "Underhand Clear",
            description: "A defensive shot played from below waist height, sending the shuttle high to the back of the opponent's court.",
            iconName: "arrow.up.forward",
            hasModelVideo: ModelVideoLoader.shared.hasModelVideo(for: "Underhand Clear")
        ),
        BadmintonTechnique(
            name: "Overhead Clear",
            description: "A powerful shot played from above the head, sending the shuttle to the back of the opponent's court.",
            iconName: "arrow.down.forward",
            hasModelVideo: ModelVideoLoader.shared.hasModelVideo(for: "Overhead Clear")
        ),
        BadmintonTechnique(
            name: "Drop Shot",
            description: "A gentle shot that just clears the net and drops sharply on the other side.",
            iconName: "arrow.down",
            hasModelVideo: ModelVideoLoader.shared.hasModelVideo(for: "Drop Shot")
        ),
        BadmintonTechnique(
            name: "Smash",
            description: "A powerful overhead shot hit steeply downward into the opponent's court.",
            iconName: "bolt.fill",
            hasModelVideo: ModelVideoLoader.shared.hasModelVideo(for: "Smash")
        ),
        BadmintonTechnique(
            name: "Net Shot",
            description: "A soft shot played near the net that just clears it and falls close to the net on the other side.",
            iconName: "power.dotted",
            hasModelVideo: ModelVideoLoader.shared.hasModelVideo(for: "Net Shot")
        )
    ]
    
    var body: some View {
        ZStack {
            ColorManager.background.ignoresSafeArea()
            
            ScrollView {
                VStack(spacing: 16) {
                    Text("Badminton Techniques")
                        .font(.title)
                        .foregroundColor(ColorManager.textPrimary)
                        .padding(.top, 24)
                    
                    Text("Select a technique to upload and analyze your form")
                        .font(.subheadline)
                        .foregroundColor(ColorManager.textSecondary)
                        .multilineTextAlignment(.center)
                        .padding(.horizontal)
                        .padding(.bottom, 12)
                    
                    LazyVStack(spacing: 16) {
                        ForEach(techniques) { technique in
                            NavigationLink(destination: TechniqueDetailView(technique: technique)) {
                                TechniqueCard(technique: technique)
                            }
                            .buttonStyle(PlainButtonStyle())
                        }
                    }
                    .padding(.horizontal, 16)
                    .padding(.bottom, 24)
                }
            }
        }
        .navigationTitle("Techniques")
        .navigationBarTitleDisplayMode(.inline)
    }
}

struct TechniqueCard: View {
    let technique: BadmintonTechnique
    
    var body: some View {
        HStack(spacing: 16) {
            // Technique icon
            ZStack {
                Circle()
                    .fill(ColorManager.accentColor.opacity(0.2))
                    .frame(width: 60, height: 60)
                
                Image(systemName: technique.iconName)
                    .font(.system(size: 24))
                    .foregroundColor(ColorManager.accentColor)
            }
            
            VStack(alignment: .leading, spacing: 4) {
                Text(technique.name)
                    .font(.headline)
                    .foregroundColor(ColorManager.textPrimary)
                
                Text(technique.description)
                    .font(.subheadline)
                    .foregroundColor(ColorManager.textSecondary)
                    .lineLimit(2)
            }
            
            Spacer()
            
            Image(systemName: "chevron.right")
                .foregroundColor(ColorManager.textSecondary)
        }
        .padding(16)
        .background(
            RoundedRectangle(cornerRadius: 12)
                .fill(ColorManager.cardBackground)
        )
    }
}

struct TechniquesListView_Previews: PreviewProvider {
    static var previews: some View {
        NavigationView {
            TechniquesListView()
        }
    }
}
</file>

<file path="MoveInsight/TechniqueVideoUploadView.swift">
import SwiftUI
import PhotosUI
import AVKit

struct TechniqueVideoUploadView: View {
    let technique: BadmintonTechnique
    let isComparison: Bool
    let onVideoSelected: (URL?) -> Void
    
    @State private var selectedItem: PhotosPickerItem?
    @State private var showPhotoPicker = false
    @State private var showPermissionAlert = false
    @State private var uploadProgress = 0.0
    
    @Environment(\.presentationMode) var presentationMode
    
    enum UploadState {
        case initial, uploading, processing, complete, error
    }
    
    @State private var state: UploadState = .initial
    
    var body: some View {
        ZStack {
            ColorManager.background.ignoresSafeArea()
            
            VStack(spacing: 24) {
                // Header
                VStack(spacing: 12) {
                    Text(isComparison ? "Upload Comparison Video" : "Upload \(technique.name) Video")
                        .font(.title2)
                        .foregroundColor(ColorManager.textPrimary)
                        .padding(.top, 16)
                    
                    Text("Select a video of yourself performing the \(technique.name) technique")
                        .font(.subheadline)
                        .foregroundColor(ColorManager.textSecondary)
                        .multilineTextAlignment(.center)
                        .padding(.horizontal)
                }
                
                Spacer()
                
                // State-dependent content
                switch state {
                case .initial:
                    // Upload button
                    Button(action: {
                        checkPermissionThenPick()
                    }) {
                        VStack(spacing: 16) {
                            Image(systemName: "video.badge.plus")
                                .font(.system(size: 40))
                                .foregroundColor(ColorManager.accentColor)
                            
                            Text("Select Video from Library")
                                .font(.headline)
                                .foregroundColor(ColorManager.textPrimary)
                        }
                        .frame(maxWidth: .infinity)
                        .padding(48)
                        .background(
                            RoundedRectangle(cornerRadius: 12)
                                .stroke(ColorManager.accentColor, lineWidth: 2)
                                .background(ColorManager.cardBackground.cornerRadius(12))
                        )
                        .padding(.horizontal, 32)
                    }
                    
                    Text("For best results, ensure your entire body is visible, and you are performing the technique from start to finish.")
                        .font(.caption)
                        .foregroundColor(ColorManager.textSecondary)
                        .multilineTextAlignment(.center)
                        .padding(.horizontal, 32)
                
                case .uploading:
                    // Upload progress
                    VStack(spacing: 16) {
                        ProgressView(value: uploadProgress)
                            .progressViewStyle(LinearProgressViewStyle(tint: ColorManager.accentColor))
                            .frame(width: 200)
                        
                        Text("Uploading... \(Int(uploadProgress * 100))%")
                            .foregroundColor(ColorManager.textPrimary)
                    }
                    
                case .processing:
                    // Processing animation
                    VStack(spacing: 16) {
                        ProgressView()
                            .progressViewStyle(CircularProgressViewStyle(tint: ColorManager.accentColor))
                            .scaleEffect(1.5)
                        
                        Text("Processing video...")
                            .foregroundColor(ColorManager.textPrimary)
                        
                        Text("Analyzing body movements and technique")
                            .font(.caption)
                            .foregroundColor(ColorManager.textSecondary)
                    }
                    
                case .complete:
                    // Success message
                    VStack(spacing: 16) {
                        Image(systemName: "checkmark.circle.fill")
                            .font(.system(size: 60))
                            .foregroundColor(.green)
                        
                        Text("Video Processed Successfully")
                            .font(.headline)
                            .foregroundColor(ColorManager.textPrimary)
                            
                        Text("Continuing in a moment...")
                            .font(.subheadline)
                            .foregroundColor(ColorManager.textSecondary)
                    }
                    
                case .error:
                    // Error message
                    VStack(spacing: 16) {
                        Image(systemName: "exclamationmark.circle.fill")
                            .font(.system(size: 60))
                            .foregroundColor(.red)
                        
                        Text("Error Processing Video")
                            .font(.headline)
                            .foregroundColor(ColorManager.textPrimary)
                        
                        Button("Try Again") {
                            state = .initial
                        }
                        .padding()
                        .background(ColorManager.accentColor)
                        .foregroundColor(.white)
                        .cornerRadius(8)
                    }
                }
                
                Spacer()
                
                // Bottom buttons
                if state == .initial {
                    Button("Cancel") {
                        presentationMode.wrappedValue.dismiss()
                    }
                    .padding()
                    .foregroundColor(ColorManager.textSecondary)
                }
            }
            .padding(.horizontal, 16)
            .padding(.bottom, 16)
        }
        .photosPicker(
            isPresented: $showPhotoPicker,
            selection: $selectedItem,
            matching: .videos
        )
        .onChange(of: selectedItem) { new in
            guard let new = new else { return }
            loadVideo(from: new)
        }
        .alert("Photo Library Access Required", isPresented: $showPermissionAlert) {
            Button("Go to Settings") {
                UIApplication.shared.open(URL(string: UIApplication.openSettingsURLString)!)
            }
            Button("Cancel", role: .cancel) { }
        }
    }
    
    // MARK: - Permissions
    private func checkPermissionThenPick() {
        let status = PHPhotoLibrary.authorizationStatus(for: .readWrite)
        switch status {
        case .authorized, .limited:
            showPhotoPicker = true
        case .notDetermined:
            PHPhotoLibrary.requestAuthorization(for: .readWrite) { st in
                DispatchQueue.main.async {
                    if st == .authorized || st == .limited {
                        showPhotoPicker = true
                    } else {
                        showPermissionAlert = true
                    }
                }
            }
        default:
            showPermissionAlert = true
        }
    }

    // MARK: - Loading & "upload"
    private func loadVideo(from item: PhotosPickerItem) {
        // reset progress
        uploadProgress = 0
        state = .uploading
        
        item.loadTransferable(type: VideoItem.self) { result in
            DispatchQueue.main.async {
                switch result {
                case .success(let vid?):
                    simulateUploadThenProcess(videoURL: vid.url)
                case .success(nil), .failure(_):
                    state = .error
                }
            }
        }
    }
    
    private func simulateUploadThenProcess(videoURL: URL) {
        // Simulate upload progress
        Timer.scheduledTimer(withTimeInterval: 0.05, repeats: true) { t in
            uploadProgress += 0.02
            if uploadProgress >= 1 {
                t.invalidate()
                // Move to processing state
                state = .processing
                
                // Simulate processing delay
                DispatchQueue.main.asyncAfter(deadline: .now() + 2.0) {
                    // Complete
                    state = .complete
                    
                    // Return the video URL to the caller but don't dismiss sheet yet
                    DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                        onVideoSelected(videoURL)
                    }
                }
            }
        }.fire()
    }
}
</file>

<file path="MoveInsight/UIComponents.swift">
import SwiftUI

// MARK: - Custom Upload Button Style
struct UploadButton: View {
    let title: LocalizedStringKey
    let iconName: String
    let action: () -> Void

    var body: some View {
        Button(action: action) {
            HStack {
                Image(systemName: iconName)
                    .font(.system(size: 22))
                Text(title)
                    .font(.headline)
            }
            .foregroundColor(.white) // Always white text
            .frame(maxWidth: .infinity)
            .padding()
            .background(ColorManager.accentColor)
            .cornerRadius(12)
        }
        .padding(.horizontal)
    }
}

// MARK: - Padding Constant
// Define standard padding to use consistently
extension CGFloat {
    static let standard: CGFloat = 16.0
}
</file>

<file path="MoveInsight/VideoPlayerRepresentable.swift">
import SwiftUI
import AVKit

// MARK: - Video Player Representable (UIViewRepresentable)
struct VideoPlayerRepresentable: UIViewRepresentable {
    let player: AVPlayer
    @Binding var videoRect: CGRect // Binding to pass videoRect back out

    // Create the custom UIView subclass
    func makeUIView(context: Context) -> PlayerUIView {
        print("Making PlayerUIView")
        let view = PlayerUIView(player: player)
        // Set the callback to update the binding
        view.onVideoRectChange = { rect in
            DispatchQueue.main.async {
                if self.videoRect != rect {
                    self.videoRect = rect
                }
            }
        }
        return view
    }

    // Update the UIView
    func updateUIView(_ uiView: PlayerUIView, context: Context) {
        if uiView.playerLayer.player !== player {
            print("Updating player instance in PlayerUIView")
            uiView.playerLayer.player = player
        }
        uiView.onVideoRectChange = { rect in
            DispatchQueue.main.async {
                if self.videoRect != rect {
                    self.videoRect = rect
                }
            }
        }
        uiView.playerLayer.videoGravity = .resizeAspect
    }
    
    // Clean up resources if needed
    static func dismantleUIView(_ uiView: PlayerUIView, coordinator: ()) {
        print("Dismantling PlayerUIView")
        uiView.playerLayer.player = nil
        uiView.onVideoRectChange = nil // Clear callback
    }
}

// MARK: - Custom UIView for AVPlayerLayer
class PlayerUIView: UIView {
    // Callback closure to report videoRect changes
    var onVideoRectChange: ((CGRect) -> Void)?
    private var lastKnownVideoRect: CGRect = .zero // Store last rect to avoid redundant callbacks

    // Override the layerClass property to specify AVPlayerLayer
    override static var layerClass: AnyClass {
        AVPlayerLayer.self
    }

    // Convenience accessor for the layer as an AVPlayerLayer
    var playerLayer: AVPlayerLayer {
        return layer as! AVPlayerLayer
    }

    // Initializer to set the player on the layer
    init(player: AVPlayer) {
        super.init(frame: .zero)
        playerLayer.player = player
        playerLayer.videoGravity = .resizeAspect // Ensure video scales correctly
        playerLayer.backgroundColor = UIColor.black.cgColor // Set background color for the layer
        self.backgroundColor = .black // Set background for the view itself
        print("PlayerUIView initialized, player assigned to layer.")
    }

    required init?(coder: NSCoder) {
        fatalError("init(coder:) has not been implemented")
    }
    
    override func layoutSubviews() {
        super.layoutSubviews()
        // Ensure the player layer's frame always matches the view's bounds
        if playerLayer.frame != self.bounds {
            print("LayoutSubviews: Updating playerLayer frame to \(self.bounds)")
            playerLayer.frame = self.bounds
        }
         
        // Get the current videoRect and report if changed
        let currentVideoRect = playerLayer.videoRect
        if currentVideoRect != lastKnownVideoRect && !currentVideoRect.isInfinite && !currentVideoRect.isNull {
            print("LayoutSubviews: videoRect changed to \(currentVideoRect)")
            lastKnownVideoRect = currentVideoRect
            onVideoRectChange?(currentVideoRect) // Call the callback
        }
    }
}
</file>

<file path="MoveInsight/VideoTransferUtils.swift">
import SwiftUI
import PhotosUI

// MARK: - VideoItem Transferable
struct VideoItem: Transferable {
    let url: URL
    
    static var transferRepresentation: some TransferRepresentation {
        FileRepresentation(contentType: .movie) { movie in
            SentTransferredFile(movie.url)
        } importing: { received in
            // Copy to a temporary location to ensure we have access
            let tempDir = FileManager.default.temporaryDirectory
            let fileName = "\(UUID().uuidString).\(received.file.pathExtension)" // Ensure unique filename
            let copyURL = tempDir.appendingPathComponent(fileName)
            
            // Attempt to remove existing file at destination URL before copying
            try? FileManager.default.removeItem(at: copyURL)

            try FileManager.default.copyItem(at: received.file, to: copyURL)
            return Self.init(url: copyURL)
        }
    }
}
</file>

<file path="MoveInsight.xcodeproj/project.xcworkspace/contents.xcworkspacedata">
<?xml version="1.0" encoding="UTF-8"?>
<Workspace
   version = "1.0">
   <FileRef
      location = "self:">
   </FileRef>
</Workspace>
</file>

<file path="MoveInsight.xcodeproj/xcuserdata/charlie.xcuserdatad/xcschemes/xcschememanagement.plist">
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>SchemeUserState</key>
	<dict>
		<key>MoveInsight.xcscheme_^#shared#^_</key>
		<dict>
			<key>orderHint</key>
			<integer>0</integer>
		</dict>
	</dict>
</dict>
</plist>
</file>

<file path="MoveInsight/Assets.xcassets/AppIcon.appiconset/Contents.json">
{
  "images" : [
    {
      "filename" : "d938011a54572aa285aa038b0f9eea3043b99b8ea3d567c2b9f568038a243413.png",
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    },
    {
      "appearances" : [
        {
          "appearance" : "luminosity",
          "value" : "dark"
        }
      ],
      "filename" : "d938011a54572aa285aa038b0f9eea3043b99b8ea3d567c2b9f568038a243413 1.png",
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    },
    {
      "appearances" : [
        {
          "appearance" : "luminosity",
          "value" : "tinted"
        }
      ],
      "filename" : "d938011a54572aa285aa038b0f9eea3043b99b8ea3d567c2b9f568038a243413 2.png",
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}
</file>

<file path="MoveInsight/BodyPoseTypes.swift">
import SwiftUI
import Vision
import simd

// MARK: - Body Connection Structure
// Defines a connection between two body joints for drawing the skeleton
struct BodyConnection: Identifiable {
    let id = UUID()
    let from: VNHumanBodyPoseObservation.JointName
    let to: VNHumanBodyPoseObservation.JointName
}

// MARK: - 3D Pose Point
// Represents a 3D pose point with position in world space
struct Pose3DPoint {
    let jointName: VNHumanBodyPoseObservation.JointName
    let position: SIMD3<Float> // x, y, z coordinates
    let confidence: Float
    
    init(jointName: VNHumanBodyPoseObservation.JointName,
         position: SIMD3<Float>,
         confidence: Float = 1.0) {
        self.jointName = jointName
        self.position = position
        self.confidence = confidence
    }
}

// MARK: - 3D Pose Body
// Represents a complete 3D human pose
struct Pose3DBody: Identifiable {
    let id = UUID()
    let joints: [VNHumanBodyPoseObservation.JointName: Pose3DPoint]
    let videoSource: VideoSource // Identifies which video this pose came from
    
    enum VideoSource {
        case primary
        case secondary
    }
    
    // Fixed initializer with proper closure parameters
    init(joints: [VNHumanBodyPoseObservation.JointName: SIMD3<Float>],
         videoSource: VideoSource) {
        self.videoSource = videoSource
        
        // Create a dictionary with jointName -> Pose3DPoint mapping
        var posePoints: [VNHumanBodyPoseObservation.JointName: Pose3DPoint] = [:]
        for (jointName, position) in joints {
            posePoints[jointName] = Pose3DPoint(jointName: jointName, position: position)
        }
        self.joints = posePoints
    }
}
</file>

<file path="MoveInsight/ContentView.swift">
import SwiftUI

struct ContentView: View {
    @State private var selectedTab = 0

    var body: some View {
        NavigationView {
            ZStack {
                // Main background
                ColorManager.background.ignoresSafeArea()

                // Content area based on selected tab
                VStack {
                    TabView(selection: $selectedTab) {
                        HomeView()
                            .tag(0)
                        
                        Text(LocalizedStringKey("Training Screen"))
                            .foregroundColor(ColorManager.textPrimary)
                            .tag(1)
                        
                        // Use the new UploadTabView directly in the Upload tab
                        UploadTabView()
                            .tag(2)
                        
                        Text(LocalizedStringKey("Videos Screen"))
                            .foregroundColor(ColorManager.textPrimary)
                            .tag(3)
                        
                        Text(LocalizedStringKey("Messages Screen"))
                            .foregroundColor(ColorManager.textPrimary)
                            .tag(4)
                    }
                    .tabViewStyle(PageTabViewStyle(indexDisplayMode: .never))
                    
                    // Custom tab bar now using the evenly-spaced implementation
                    CustomTabBar(selectedTab: $selectedTab)
                }
            }
            .navigationBarHidden(true)
        }
    }
}

// MARK: - Previews
struct ContentView_Previews: PreviewProvider {
    static var previews: some View {
        ContentView()
            .preferredColorScheme(.dark)
    }
}
</file>

<file path="MoveInsight/Extensions.swift">
import SwiftUI
import Combine

// MARK: - Publisher Extension
extension AnyCancellable {
    func cancel(after interval: TimeInterval) {
        DispatchQueue.main.asyncAfter(deadline: .now() + interval) {
            self.cancel()
        }
    }
}

// MARK: - View Extensions
extension View {
    // Apply a conditional modifier
    @ViewBuilder func applyIf<Content: View>(_ condition: Bool, content: (Self) -> Content) -> some View {
        if condition {
            content(self)
        } else {
            self
        }
    }
    
    // Add a shake effect to a view
    func shake(amount: CGFloat = 5, shakesPerUnit: CGFloat = 3, animationDuration: CGFloat = 0.7, isShaking: Bool = true) -> some View {
        self.modifier(ShakeEffect(amount: amount, shakesPerUnit: shakesPerUnit, animationDuration: animationDuration, isShaking: isShaking))
    }
}

// MARK: - Navigation Extensions
extension View {
    // Create a navigation link that's programmatically triggered
    func navigationLinkWithDestination<Destination: View>(isActive: Binding<Bool>, @ViewBuilder destination: @escaping () -> Destination) -> some View {
        ZStack {
            self
            
            NavigationLink(
                destination: destination(),
                isActive: isActive
            ) {
                EmptyView()
            }
            .hidden()
        }
    }
}

// MARK: - Shake Effect Modifier
struct ShakeEffect: ViewModifier {
    var amount: CGFloat = 5
    var shakesPerUnit: CGFloat = 3
    var animationDuration: CGFloat = 0.7
    var isShaking: Bool = true
    
    func body(content: Content) -> some View {
        content
            .offset(x: isShaking ? amount * sin(shakesPerUnit * .pi * animationDuration) : 0)
            .animation(
                isShaking ?
                    Animation.easeInOut(duration: animationDuration)
                    .repeatForever(autoreverses: true) :
                    .default,
                value: isShaking
            )
    }
}

// MARK: - Dynamic Height Modifier
struct DynamicHeightModifier: ViewModifier {
    @Binding var height: CGFloat
    
    func body(content: Content) -> some View {
        content
            .background(
                GeometryReader { geometry -> Color in
                    DispatchQueue.main.async {
                        self.height = geometry.size.height
                    }
                    return Color.clear
                }
            )
    }
}
</file>

<file path="MoveInsight/HomeView.swift">
import SwiftUI

struct HomeView: View {
    // Sample user data – name typically wouldn't be localized
    let username = "Zhang Wei"
    
    var body: some View {
        ZStack {
            // Main background
            ColorManager.background.ignoresSafeArea()
            
            // Content
            ScrollView {
                VStack(alignment: .leading, spacing: 24) {
                    // User greeting
                    HStack {
                        VStack(alignment: .leading) {
                            Text(LocalizedStringKey("Good morning,"))
                                .font(.system(size: 16))
                                .foregroundColor(ColorManager.textSecondary)
                            Text(username)
                                .font(.system(size: 24, weight: .bold))
                                .foregroundColor(ColorManager.textPrimary)
                        }
                        
                        Spacer()
                        
                        // Profile image
                        Image(systemName: "person.crop.circle.fill")
                            .resizable()
                            .frame(width: 40, height: 40)
                            .foregroundColor(ColorManager.accentColor)
                            .background(ColorManager.cardBackground)
                            .clipShape(Circle())
                    }
                    .padding(.top, 12)
                    
                    // Match Performance Card
                    PerformanceCard()
                    
                    // Technicals Section - Updated to navigate to TechniquesListView
                    NavigationLink(destination: TechniquesListView()) {
                        SectionCard(title: LocalizedStringKey("Technicals"))
                    }
                    
                    // Training Goals
                    NavigationLink(destination: Text(LocalizedStringKey("Training Goals Detail"))) {
                        GoalsCard()
                    }
                    
                    // Tutorials Section
                    Text(LocalizedStringKey("Tutorials Specifically For You"))
                        .font(.headline)
                        .foregroundColor(ColorManager.textPrimary)
                        .padding(.top, 5)
                }
                .padding(.horizontal, 16)
                .padding(.bottom, 20)
            }
        }
    }
}

// MARK: - Performance Card
struct PerformanceCard: View {
    var body: some View {
        VStack(alignment: .leading, spacing: 15) {
            HStack {
                Text(LocalizedStringKey("Match Performance"))
                    .font(.headline)
                    .foregroundColor(ColorManager.textPrimary)
                
                Spacer()
                
                Image(systemName: "arrow.up.right.square")
                    .foregroundColor(ColorManager.textSecondary)
            }
            
            HStack(alignment: .top, spacing: 15) {
                // Improvement stat
                VStack(alignment: .leading, spacing: 2) {
                    HStack {
                        Image(systemName: "chart.line.uptrend.xyaxis")
                            .foregroundColor(ColorManager.accentColor)
                        
                        Text(LocalizedStringKey("2.3%"))
                            .fontWeight(.bold)
                            .foregroundColor(ColorManager.textPrimary)
                    }
                    
                    Text(LocalizedStringKey("/ last week"))
                        .font(.caption)
                        .foregroundColor(ColorManager.textSecondary)
                    
                    Text(LocalizedStringKey("Well done on swing path!"))
                        .font(.caption)
                        .foregroundColor(ColorManager.textSecondary)
                        .padding(.top, 5)
                }
                
                Spacer()
                
                // Rating gauge using only purple with a gradient
                ZStack {
                    Circle()
                        .trim(from: 0, to: 0.75)
                        .stroke(
                            AngularGradient(
                                gradient: Gradient(colors: [ColorManager.accentColor.opacity(0.6), ColorManager.accentColor]),
                                center: .center,
                                startAngle: .degrees(0),
                                endAngle: .degrees(270)
                            ),
                            style: StrokeStyle(lineWidth: 8, lineCap: .round)
                        )
                        .frame(width: 80, height: 80)
                        .rotationEffect(.degrees(135))
                    
                    Text(LocalizedStringKey("4.3"))
                        .font(.system(size: 24, weight: .bold))
                        .foregroundColor(ColorManager.textPrimary)
                }
            }
            
            // Progress chart
            Chart()
                .frame(height: 120)
                .padding(.vertical, 8)
            
            // Match history link
            HStack {
                Text(LocalizedStringKey("Match History"))
                    .foregroundColor(ColorManager.textSecondary)
                    .font(.subheadline)
                
                Spacer()
                
                Image(systemName: "chevron.right")
                    .foregroundColor(ColorManager.textSecondary)
                    .font(.caption)
            }
        }
        .padding(20)
        .background(
            RoundedRectangle(cornerRadius: 16)
                .fill(ColorManager.cardBackground.opacity(0.8))
        )
    }
}

// MARK: - Simple Chart Component
struct Chart: View {
    let months = ["Jan", "Feb", "Mar", "Apr", "May"]
    
    var body: some View {
        GeometryReader { geometry in
            let width = geometry.size.width
            let height = geometry.size.height
            
            HStack(spacing: 0) {
                ForEach(months, id: \.self) { month in
                    Text(LocalizedStringKey(month))
                        .font(.system(size: 8))
                        .foregroundColor(ColorManager.textSecondary)
                        .frame(width: width / CGFloat(months.count))
                }
            }
            .position(x: width / 2, y: height - 5)
            
            VStack(spacing: 8) {
                ForEach(["4", "3", "2", "1", "0"], id: \.self) { value in
                    Text(value)
                        .font(.system(size: 8))
                        .foregroundColor(ColorManager.textSecondary)
                }
            }
            .position(x: 8, y: height / 2)
            
            Path { path in
                let points = [
                    CGPoint(x: width * 0.1, y: height * 0.7),
                    CGPoint(x: width * 0.3, y: height * 0.5),
                    CGPoint(x: width * 0.5, y: height * 0.4),
                    CGPoint(x: width * 0.7, y: height * 0.35),
                    CGPoint(x: width * 0.9, y: height * 0.3)
                ]
                
                path.move(to: points[0])
                for point in points.dropFirst() {
                    path.addLine(to: point)
                }
            }
            .stroke(ColorManager.textPrimary, lineWidth: 1.5)
        }
    }
}

// MARK: - Section Card
struct SectionCard: View {
    let title: LocalizedStringKey
    
    var body: some View {
        HStack {
            Text(title)
                .font(.headline)
                .foregroundColor(ColorManager.textPrimary)
            
            Spacer()
            
            Image(systemName: "chevron.right")
                .foregroundColor(ColorManager.textSecondary)
        }
        .padding(20)
        .background(
            RoundedRectangle(cornerRadius: 16)
                .fill(ColorManager.cardBackground.opacity(0.8))
        )
    }
}

// MARK: - Goals Card
struct GoalsCard: View {
    var body: some View {
        HStack {
            VStack(alignment: .leading) {
                Text(LocalizedStringKey("Training Goals"))
                    .font(.headline)
                    .foregroundColor(ColorManager.textPrimary)
                
                HStack(spacing: 8) {
                    ForEach(0..<4) { _ in
                        Image(systemName: "checkmark.circle.fill")
                            .foregroundColor(.green)
                    }
                    
                    Image(systemName: "checkmark.circle.fill")
                        .foregroundColor(ColorManager.textSecondary.opacity(0.5))
                }
            }
            
            Spacer()
            
            Image(systemName: "chevron.right")
                .foregroundColor(ColorManager.textSecondary)
        }
        .padding(20)
        .background(
            RoundedRectangle(cornerRadius: 16)
                .fill(ColorManager.cardBackground.opacity(0.8))
        )
    }
}
</file>

<file path="MoveInsight/MoveInsightApp.swift">
import SwiftUI

@main
struct MoveInsightApp: App {
    init() {
        // Set the accent color for the entire app
        UINavigationBar.appearance().tintColor = UIColor(Color.accentColor)
    }
    
    var body: some Scene {
        WindowGroup {
            ContentView()
                .accentColor(ColorManager.accentColor)
        }
    }
}

// For iOS 17+, we can use the newer API too
#if swift(>=5.9)
extension MoveInsightApp {
    @ViewBuilder
    private func contentWithTint() -> some View {
        if #available(iOS 17.0, *) {
            ContentView()
                .preferredColorScheme(.dark)
                .tint(ColorManager.accentColor)
        } else {
            ContentView()
                .preferredColorScheme(.dark)
                .accentColor(ColorManager.accentColor)
        }
    }
}
#endif
</file>

<file path="MoveInsight/UploadTabView.swift">
import SwiftUI
import PhotosUI
import AVKit

struct UploadTabView: View {
    @State private var navigateToTechniquesList = false
    
    var body: some View {
        NavigationView {
            ZStack {
                ColorManager.background.ignoresSafeArea()
                
                VStack(spacing: 30) {
                    // Header
                    Text("Upload Video")
                        .font(.title)
                        .foregroundColor(ColorManager.textPrimary)
                        .padding(.top, 40)
                    
                    Text("Choose the type of video you want to upload")
                        .font(.subheadline)
                        .foregroundColor(ColorManager.textSecondary)
                        .multilineTextAlignment(.center)
                        .padding(.horizontal, 32)
                    
                    Spacer()
                    
                    // Technique Video Option
                    NavigationLink(destination: TechniquesListView(), isActive: $navigateToTechniquesList) {
                        EmptyView()
                    }
                    
                    Button(action: {
                        navigateToTechniquesList = true
                    }) {
                        UploadOptionCard(
                            title: "Upload Technique Video",
                            description: "Analyze and compare your badminton techniques with model performers",
                            icon: "figure.badminton"
                        )
                    }
                    .buttonStyle(ScaleButtonStyle())
                    
                    // Match Video Option
                    Button(action: {
                        // Do nothing for now, as per requirements
                    }) {
                        UploadOptionCard(
                            title: "Upload Match Video",
                            description: "Upload your match videos for performance analysis",
                            icon: "sportscourt"
                        )
                    }
                    .buttonStyle(ScaleButtonStyle())
                    
                    Spacer()
                }
                .padding(.horizontal, 20)
            }
            .navigationBarHidden(true)
        }
    }
}

// Card view for upload options
struct UploadOptionCard: View {
    let title: String
    let description: String
    let icon: String
    
    var body: some View {
        HStack(spacing: 20) {
            // Icon
            ZStack {
                Circle()
                    .fill(ColorManager.accentColor.opacity(0.2))
                    .frame(width: 70, height: 70)
                
                Image(systemName: icon)
                    .font(.system(size: 30))
                    .foregroundColor(ColorManager.accentColor)
            }
            
            // Text content
            VStack(alignment: .leading, spacing: 8) {
                Text(title)
                    .font(.headline)
                    .foregroundColor(ColorManager.textPrimary)
                
                Text(description)
                    .font(.subheadline)
                    .foregroundColor(ColorManager.textSecondary)
                    .lineLimit(2)
            }
            
            Spacer()
            
            // Arrow
            Image(systemName: "chevron.right")
                .foregroundColor(ColorManager.textSecondary)
        }
        .padding(20)
        .background(
            RoundedRectangle(cornerRadius: 16)
                .fill(ColorManager.cardBackground)
        )
    }
}

// Button style with scale effect
struct ScaleButtonStyle: ButtonStyle {
    func makeBody(configuration: Configuration) -> some View {
        configuration.label
            .scaleEffect(configuration.isPressed ? 0.97 : 1.0)
            .animation(.easeInOut(duration: 0.2), value: configuration.isPressed)
    }
}
</file>

<file path="MoveInsight/VideoPlayerViewModel.swift">
import SwiftUI
import AVKit
import Vision
import Combine
import simd

// MARK: - Video Player View Model
class VideoPlayerViewModel: ObservableObject {
    let videoURL: URL
    let player: AVPlayer
    let asset: AVAsset

    // Published properties to update the UI
    @Published var poses: [[VNHumanBodyPoseObservation.JointName: CGPoint]] = []
    @Published var pose3DBodies: [Pose3DBody] = []
    @Published var bodyConnections: [BodyConnection] = []
    @Published var isVideoReady = false
    @Published var isPlaying = false
    @Published var videoOrientation: CGImagePropertyOrientation = .up
    @Published var currentDepthMap: MLMultiArray?
    @Published var depthImage: UIImage?
    
    @Published var currentDepthBuffer: CVPixelBuffer?
    
    // Current video properties
    private(set) var videoSize: CGSize = .zero
    
    // Source identifier for 3D poses
    let videoSource: Pose3DBody.VideoSource
    
    // Services
    private let depthEstimationService = DepthEstimationService()
    private let pose3DProcessor = Pose3DProcessor()

    private var playerItemVideoOutput: AVPlayerItemVideoOutput?
    private var displayLink: CADisplayLink?
    private var playerItemStatusObserver: NSKeyValueObservation?
    private var cancellables = Set<AnyCancellable>()

    // Vision request handler
    private let visionSequenceHandler = VNSequenceRequestHandler()
    // Configure the request for multi-person detection
    private let bodyPoseRequest: VNDetectHumanBodyPoseRequest = {
        let request = VNDetectHumanBodyPoseRequest()
        return request
    }()
    
    // Add property to accumulate poses over time
    private var accumulatedPoses: [[VNHumanBodyPoseObservation.JointName: CGPoint]] = []
    private let maxFrames = 300 // Limit to 300 frames (10 seconds at 30fps)
    
    // Method to get all accumulated poses
    func getAllPoses() -> [[VNHumanBodyPoseObservation.JointName: CGPoint]] {
        return accumulatedPoses
    }
    
    // Method to clear accumulated poses
    func clearAccumulatedPoses() {
        print("Clearing accumulated poses")
        accumulatedPoses.removeAll()
    }

    init(videoURL: URL, videoSource: Pose3DBody.VideoSource) {
        self.videoURL = videoURL
        self.asset = AVAsset(url: videoURL)
        self.player = AVPlayer()
        self.videoSource = videoSource

        print("VideoPlayerViewModel initialized with URL: \(videoURL.path)")

        setupBodyConnections()
        prepareVideoPlayback()
    }

    // Define the connections for the skeleton overlay
    private func setupBodyConnections() {
        bodyConnections = [
            .init(from: .nose, to: .neck),
            .init(from: .neck, to: .rightShoulder),
            .init(from: .neck, to: .leftShoulder),
            .init(from: .rightShoulder, to: .rightHip),
            .init(from: .leftShoulder, to: .leftHip),
            .init(from: .rightHip, to: .leftHip),
            .init(from: .rightShoulder, to: .rightElbow),
            .init(from: .rightElbow, to: .rightWrist),
            .init(from: .leftShoulder, to: .leftElbow),
            .init(from: .leftElbow, to: .leftWrist),
            .init(from: .rightHip, to: .rightKnee),
            .init(from: .rightKnee, to: .rightAnkle),
            .init(from: .leftHip, to: .leftKnee),
            .init(from: .leftKnee, to: .leftAnkle)
        ]
    }

    // Prepare the AVPlayerItem and related components
    private func prepareVideoPlayback() {
        // Asynchronously load asset properties (tracks and duration)
        Task {
            do {
                // Load tracks to get orientation and dimensions
                let tracks = try await asset.load(.tracks)
                
                // Find the video track and determine orientation and size
                if let videoTrack = tracks.first(where: { $0.mediaType == .video }) {
                    let transform = try await videoTrack.load(.preferredTransform)
                    let orientation = orientation(from: transform)
                    
                    // Get video dimensions
                    let size = try await videoTrack.load(.naturalSize)
                    
                    // Update on the main thread
                    await MainActor.run {
                        print("Determined video orientation: \(orientation.rawValue)")
                        self.videoOrientation = orientation
                        self.videoSize = size
                        // Now that orientation is known, create player item and setup player
                        self.setupPlayerItemAndObservers()
                    }
                } else {
                    print("Error: No video track found in asset.")
                    await MainActor.run { self.isVideoReady = false }
                }
            } catch {
                print("Error loading asset tracks or transform: \(error)")
                await MainActor.run { self.isVideoReady = false }
            }
        }
    }
    
    // Sets up the player item and observers AFTER orientation is determined
    private func setupPlayerItemAndObservers() {
        let playerItem = AVPlayerItem(asset: asset)
        
        // 1. Observe PlayerItem Status
        playerItemStatusObserver = playerItem.observe(\.status, options: [.new, .initial]) { [weak self] item, _ in
            guard let self = self else { return }
            DispatchQueue.main.async {
                print("PlayerItem status changed: \(item.status.rawValue)")
                switch item.status {
                case .readyToPlay:
                    print("PlayerItem is ready to play.")
                    self.isVideoReady = true
                    self.setupPlayerOutput(for: item)
                    self.setupDisplayLink()
                case .failed:
                    print("PlayerItem failed to load: \(item.error?.localizedDescription ?? "Unknown error")")
                    self.isVideoReady = false
                case .unknown:
                    print("PlayerItem status is unknown.")
                    self.isVideoReady = false
                @unknown default:
                    self.isVideoReady = false
                }
            }
        }

        // 2. Observe Playback End
        NotificationCenter.default.addObserver(forName: .AVPlayerItemDidPlayToEndTime, object: playerItem, queue: .main) { [weak self] _ in
            print("Video finished playing.")
            self?.isPlaying = false
            self?.player.seek(to: .zero)
        }
        
        // Replace the player's current item
        player.replaceCurrentItem(with: playerItem)
        
        // Ensure audio plays if present
        player.volume = 1.0
        player.allowsExternalPlayback = true
    }

    // Setup the AVPlayerItemVideoOutput to grab frames
    private func setupPlayerOutput(for item: AVPlayerItem) {
        // Check if output already exists for this item
        if item.outputs.contains(where: { $0 is AVPlayerItemVideoOutput }) {
            print("AVPlayerItemVideoOutput already added.")
            playerItemVideoOutput = item.outputs.first(where: { $0 is AVPlayerItemVideoOutput }) as? AVPlayerItemVideoOutput
            return
        }
        
        let pixelBufferAttributes = [
            kCVPixelBufferPixelFormatTypeKey as String: Int(kCVPixelFormatType_32BGRA),
            kCVPixelBufferIOSurfacePropertiesKey as String: [:]
        ] as [String : Any]
        playerItemVideoOutput = AVPlayerItemVideoOutput(pixelBufferAttributes: pixelBufferAttributes)

        if let output = playerItemVideoOutput {
            print("Adding AVPlayerItemVideoOutput to player item.")
            item.add(output)
        } else {
            print("Error: Failed to create AVPlayerItemVideoOutput.")
        }
    }

    // Setup the CADisplayLink for frame-synchronized processing
    private func setupDisplayLink() {
        // Invalidate existing link if any
        displayLink?.invalidate()

        // Create a new display link targeting the frame processing method
        displayLink = CADisplayLink(target: self, selector: #selector(displayLinkDidFire))
        displayLink?.add(to: .main, forMode: .common)
        print("CADisplayLink setup.")
    }

    // Called by the CADisplayLink on every screen refresh
    @objc private func displayLinkDidFire(_ link: CADisplayLink) {
        // Ensure player item output exists and player is playing
        guard let output = playerItemVideoOutput, player.timeControlStatus == .playing else { return }

        // Get the current time for the host clock
        let currentTime = CACurrentMediaTime()
        // Ask the output for the item time corresponding to the host time
        let itemTime = output.itemTime(forHostTime: currentTime)

        // Check if there's a new pixel buffer available for this time
        if output.hasNewPixelBuffer(forItemTime: itemTime) {
            // Copy the pixel buffer if available
            if let pixelBuffer = output.copyPixelBuffer(forItemTime: itemTime, itemTimeForDisplay: nil) {
                // Process this frame using Vision, passing the DETECTED orientation
                processFrame(pixelBuffer, orientation: self.videoOrientation)
            }
        }
    }

    // Process a single video frame with Vision to detect body pose and estimate depth
    private func processFrame(_ pixelBuffer: CVPixelBuffer, orientation: CGImagePropertyOrientation) {
        // 1. Detect 2D poses
        process2DPoses(pixelBuffer, orientation: orientation)
        
        // 2. Estimate depth
        if let depthBuffer = depthEstimationService.estimateDepth(from: pixelBuffer) {
            DispatchQueue.main.async {
                self.currentDepthBuffer = depthBuffer
                self.depthImage = self.depthEstimationService.depthMapToImage(from: depthBuffer)
                
                // 3. Combine 2D poses and depth to create 3D poses
                if !self.poses.isEmpty {
                    let pose3DBodies = self.pose3DProcessor.process(
                        poses: self.poses,
                        depthBuffer: depthBuffer,
                        videoSize: self.videoSize
                    ).map { Pose3DBody(joints: $0, videoSource: self.videoSource) }
                    
                    self.pose3DBodies = pose3DBodies
                }
            }
        }
    }
    
    // Process 2D poses with Vision
    private func process2DPoses(_ pixelBuffer: CVPixelBuffer, orientation: CGImagePropertyOrientation) {
        do {
            // Perform request with the correct orientation
            try visionSequenceHandler.perform([bodyPoseRequest], on: pixelBuffer, orientation: orientation)

            // Get the results from the request (potentially multiple observations)
            guard let results = bodyPoseRequest.results else {
                // No results, clear poses
                DispatchQueue.main.async {
                    if !self.poses.isEmpty {
                        self.poses = []
                    }
                }
                return
            }

            // Multi-person processing
            var detectedPoses: [[VNHumanBodyPoseObservation.JointName: CGPoint]] = []
            for observation in results {
                let points = extractPoints(from: observation)
                if !points.isEmpty {
                    detectedPoses.append(points)
                }
            }

            // Update the published property on the main thread
            DispatchQueue.main.async {
                // Update current frame poses
                self.poses = detectedPoses
                
                // Add these poses to our accumulated history
                if !detectedPoses.isEmpty {
                    // For simplicity, just take the first person detected in the frame
                    if let firstPersonPose = detectedPoses.first {
                        // Limit to maxFrames
                        if self.accumulatedPoses.count >= self.maxFrames {
                            // Remove oldest frame
                            self.accumulatedPoses.removeFirst()
                        }
                        // Add the new frame's pose
                        self.accumulatedPoses.append(firstPersonPose)
                        
                        if self.accumulatedPoses.count % 30 == 0 {  // Log every 30 frames
                            print("Accumulated \(self.accumulatedPoses.count) frames with poses.")
                        }
                    }
                }
                
                // if this is the very first frame, let the UI know it's ready
                if !detectedPoses.isEmpty && !self.isVideoReady {
                    self.isVideoReady = true
                }
            }
        } catch {
            print("Vision performance error: \(error)")
        }
    }

    // Extract joint points from a SINGLE VNHumanBodyPoseObservation
    private func extractPoints(from observation: VNHumanBodyPoseObservation) -> [VNHumanBodyPoseObservation.JointName: CGPoint] {
        var detectedPoints: [VNHumanBodyPoseObservation.JointName: CGPoint] = [:]

        do {
            // Get the recognized points for all available joints in this observation
            let recognizedPoints = try observation.recognizedPoints(.all)

            for (jointName, point) in recognizedPoints {
                // Filter by confidence threshold
                if point.confidence > 0.1 {
                    // Convert to SwiftUI coordinates by flipping Y
                    detectedPoints[jointName] = CGPoint(x: point.location.x, y: 1.0 - point.location.y)
                }
            }
        } catch {
            print("Error getting recognized points for an observation: \(error)")
        }

        return detectedPoints
    }
    
    // Helper function to determine CGImagePropertyOrientation from CGAffineTransform
    private func orientation(from transform: CGAffineTransform) -> CGImagePropertyOrientation {
        let t = transform
        // Analyze the transform matrix to determine orientation
        switch (t.a, t.b, t.c, t.d) {
        case (0.0, 1.0, -1.0, 0.0): // Portrait
            return .right
        case (0.0, -1.0, 1.0, 0.0): // Portrait (Upside Down)
            return .left
        case (-1.0, 0.0, 0.0, -1.0): // Landscape (Left)
            return .down
        case (1.0, 0.0, 0.0, 1.0): // Landscape (Right) - Identity
            return .up
        default: // Default orientation if transform doesn't match known patterns
            print("Warning: Unknown CGAffineTransform found: \(t). Defaulting to .up orientation.")
            return .up
        }
    }

    // MARK: - Playback Control Methods
    func play() {
        if isVideoReady {
            print("Playing video.")
            player.play()
            isPlaying = true
            if displayLink == nil || displayLink?.isPaused == true {
                setupDisplayLink()
            }
            displayLink?.isPaused = false
        } else {
            print("Attempted to play before video was ready.")
        }
    }

    func pause() {
        print("Pausing video.")
        player.pause()
        isPlaying = false
        displayLink?.isPaused = true
    }

    func togglePlayPause() {
        if isPlaying {
            pause()
        } else {
            play()
        }
    }
    
    func restart() {
        print("Restarting video.")
        player.seek(to: .zero) { [weak self] finished in
            if finished {
                self?.play()
            }
        }
    }

    // Clean up resources when the ViewModel is deallocated
    func cleanup() {
        print("Cleaning up VideoPlayerViewModel.")
        // Stop playback
        player.pause()
        isPlaying = false

        // Invalidate display link
        displayLink?.invalidate()
        displayLink = nil

        // Remove KVO observer
        playerItemStatusObserver?.invalidate()
        playerItemStatusObserver = nil

        // Remove NotificationCenter observer
        NotificationCenter.default.removeObserver(self, name: .AVPlayerItemDidPlayToEndTime, object: player.currentItem)
        
        // Cancel Combine subscriptions
        cancellables.forEach { $0.cancel() }
        cancellables.removeAll()

        // Remove video output from player item
        if let output = playerItemVideoOutput, let item = player.currentItem {
            print("Removing AVPlayerItemVideoOutput.")
            item.remove(output)
        }
        playerItemVideoOutput = nil
        
        // Clear accumulated poses
        accumulatedPoses.removeAll()
        
        // Nil out player and item to break potential retain cycles
        player.replaceCurrentItem(with: nil)
    }

    deinit {
        print("VideoPlayerViewModel deinit")
        cleanup()
    }
}
</file>

<file path="MoveInsight.xcodeproj/project.pbxproj">
// !$*UTF8*$!
{
	archiveVersion = 1;
	classes = {
	};
	objectVersion = 77;
	objects = {

/* Begin PBXFileReference section */
		CB1C3FAE2D9D493B008FC7AB /* MoveInsight.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = MoveInsight.app; sourceTree = BUILT_PRODUCTS_DIR; };
/* End PBXFileReference section */

/* Begin PBXFileSystemSynchronizedBuildFileExceptionSet section */
		CB6878622DD191DB00A36A08 /* Exceptions for "MoveInsight" folder in "MoveInsight" target */ = {
			isa = PBXFileSystemSynchronizedBuildFileExceptionSet;
			membershipExceptions = (
				Info.plist,
			);
			target = CB1C3FAD2D9D493B008FC7AB /* MoveInsight */;
		};
/* End PBXFileSystemSynchronizedBuildFileExceptionSet section */

/* Begin PBXFileSystemSynchronizedRootGroup section */
		CB1C3FB02D9D493B008FC7AB /* MoveInsight */ = {
			isa = PBXFileSystemSynchronizedRootGroup;
			exceptions = (
				CB6878622DD191DB00A36A08 /* Exceptions for "MoveInsight" folder in "MoveInsight" target */,
			);
			path = MoveInsight;
			sourceTree = "<group>";
		};
/* End PBXFileSystemSynchronizedRootGroup section */

/* Begin PBXFrameworksBuildPhase section */
		CB1C3FAB2D9D493B008FC7AB /* Frameworks */ = {
			isa = PBXFrameworksBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXFrameworksBuildPhase section */

/* Begin PBXGroup section */
		CB1C3FA52D9D493B008FC7AB = {
			isa = PBXGroup;
			children = (
				CB1C3FB02D9D493B008FC7AB /* MoveInsight */,
				CB1C3FAF2D9D493B008FC7AB /* Products */,
			);
			sourceTree = "<group>";
		};
		CB1C3FAF2D9D493B008FC7AB /* Products */ = {
			isa = PBXGroup;
			children = (
				CB1C3FAE2D9D493B008FC7AB /* MoveInsight.app */,
			);
			name = Products;
			sourceTree = "<group>";
		};
/* End PBXGroup section */

/* Begin PBXNativeTarget section */
		CB1C3FAD2D9D493B008FC7AB /* MoveInsight */ = {
			isa = PBXNativeTarget;
			buildConfigurationList = CB1C3FBC2D9D493D008FC7AB /* Build configuration list for PBXNativeTarget "MoveInsight" */;
			buildPhases = (
				CB1C3FAA2D9D493B008FC7AB /* Sources */,
				CB1C3FAB2D9D493B008FC7AB /* Frameworks */,
				CB1C3FAC2D9D493B008FC7AB /* Resources */,
			);
			buildRules = (
			);
			dependencies = (
			);
			fileSystemSynchronizedGroups = (
				CB1C3FB02D9D493B008FC7AB /* MoveInsight */,
			);
			name = MoveInsight;
			packageProductDependencies = (
			);
			productName = MoveInsight;
			productReference = CB1C3FAE2D9D493B008FC7AB /* MoveInsight.app */;
			productType = "com.apple.product-type.application";
		};
/* End PBXNativeTarget section */

/* Begin PBXProject section */
		CB1C3FA62D9D493B008FC7AB /* Project object */ = {
			isa = PBXProject;
			attributes = {
				BuildIndependentTargetsInParallel = 1;
				LastSwiftUpdateCheck = 1610;
				LastUpgradeCheck = 1610;
				TargetAttributes = {
					CB1C3FAD2D9D493B008FC7AB = {
						CreatedOnToolsVersion = 16.1;
					};
				};
			};
			buildConfigurationList = CB1C3FA92D9D493B008FC7AB /* Build configuration list for PBXProject "MoveInsight" */;
			developmentRegion = en;
			hasScannedForEncodings = 0;
			knownRegions = (
				en,
				Base,
				"zh-Hans",
			);
			mainGroup = CB1C3FA52D9D493B008FC7AB;
			minimizedProjectReferenceProxies = 1;
			preferredProjectObjectVersion = 77;
			productRefGroup = CB1C3FAF2D9D493B008FC7AB /* Products */;
			projectDirPath = "";
			projectRoot = "";
			targets = (
				CB1C3FAD2D9D493B008FC7AB /* MoveInsight */,
			);
		};
/* End PBXProject section */

/* Begin PBXResourcesBuildPhase section */
		CB1C3FAC2D9D493B008FC7AB /* Resources */ = {
			isa = PBXResourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXResourcesBuildPhase section */

/* Begin PBXSourcesBuildPhase section */
		CB1C3FAA2D9D493B008FC7AB /* Sources */ = {
			isa = PBXSourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXSourcesBuildPhase section */

/* Begin XCBuildConfiguration section */
		CB1C3FBA2D9D493D008FC7AB /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				ASSETCATALOG_COMPILER_GENERATE_SWIFT_ASSET_SYMBOL_EXTENSIONS = YES;
				CLANG_ANALYZER_NONNULL = YES;
				CLANG_ANALYZER_NUMBER_OBJECT_CONVERSION = YES_AGGRESSIVE;
				CLANG_CXX_LANGUAGE_STANDARD = "gnu++20";
				CLANG_ENABLE_MODULES = YES;
				CLANG_ENABLE_OBJC_ARC = YES;
				CLANG_ENABLE_OBJC_WEAK = YES;
				CLANG_WARN_BLOCK_CAPTURE_AUTORELEASING = YES;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_COMMA = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_DEPRECATED_OBJC_IMPLEMENTATIONS = YES;
				CLANG_WARN_DIRECT_OBJC_ISA_USAGE = YES_ERROR;
				CLANG_WARN_DOCUMENTATION_COMMENTS = YES;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INFINITE_RECURSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN_NON_LITERAL_NULL_CONVERSION = YES;
				CLANG_WARN_OBJC_IMPLICIT_RETAIN_SELF = YES;
				CLANG_WARN_OBJC_LITERAL_CONVERSION = YES;
				CLANG_WARN_OBJC_ROOT_CLASS = YES_ERROR;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = YES;
				CLANG_WARN_RANGE_LOOP_ANALYSIS = YES;
				CLANG_WARN_STRICT_PROTOTYPES = YES;
				CLANG_WARN_SUSPICIOUS_MOVE = YES;
				CLANG_WARN_UNGUARDED_AVAILABILITY = YES_AGGRESSIVE;
				CLANG_WARN_UNREACHABLE_CODE = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				COPY_PHASE_STRIP = NO;
				DEBUG_INFORMATION_FORMAT = dwarf;
				ENABLE_STRICT_OBJC_MSGSEND = YES;
				ENABLE_TESTABILITY = YES;
				ENABLE_USER_SCRIPT_SANDBOXING = YES;
				GCC_C_LANGUAGE_STANDARD = gnu17;
				GCC_DYNAMIC_NO_PIC = NO;
				GCC_NO_COMMON_BLOCKS = YES;
				GCC_OPTIMIZATION_LEVEL = 0;
				GCC_PREPROCESSOR_DEFINITIONS = (
					"DEBUG=1",
					"$(inherited)",
				);
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES_ERROR;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				IPHONEOS_DEPLOYMENT_TARGET = 18.1;
				LOCALIZATION_PREFERS_STRING_CATALOGS = YES;
				MTL_ENABLE_DEBUG_INFO = INCLUDE_SOURCE;
				MTL_FAST_MATH = YES;
				ONLY_ACTIVE_ARCH = YES;
				SDKROOT = iphoneos;
				SWIFT_ACTIVE_COMPILATION_CONDITIONS = "DEBUG $(inherited)";
				SWIFT_OPTIMIZATION_LEVEL = "-Onone";
			};
			name = Debug;
		};
		CB1C3FBB2D9D493D008FC7AB /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				ASSETCATALOG_COMPILER_GENERATE_SWIFT_ASSET_SYMBOL_EXTENSIONS = YES;
				CLANG_ANALYZER_NONNULL = YES;
				CLANG_ANALYZER_NUMBER_OBJECT_CONVERSION = YES_AGGRESSIVE;
				CLANG_CXX_LANGUAGE_STANDARD = "gnu++20";
				CLANG_ENABLE_MODULES = YES;
				CLANG_ENABLE_OBJC_ARC = YES;
				CLANG_ENABLE_OBJC_WEAK = YES;
				CLANG_WARN_BLOCK_CAPTURE_AUTORELEASING = YES;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_COMMA = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_DEPRECATED_OBJC_IMPLEMENTATIONS = YES;
				CLANG_WARN_DIRECT_OBJC_ISA_USAGE = YES_ERROR;
				CLANG_WARN_DOCUMENTATION_COMMENTS = YES;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INFINITE_RECURSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN_NON_LITERAL_NULL_CONVERSION = YES;
				CLANG_WARN_OBJC_IMPLICIT_RETAIN_SELF = YES;
				CLANG_WARN_OBJC_LITERAL_CONVERSION = YES;
				CLANG_WARN_OBJC_ROOT_CLASS = YES_ERROR;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = YES;
				CLANG_WARN_RANGE_LOOP_ANALYSIS = YES;
				CLANG_WARN_STRICT_PROTOTYPES = YES;
				CLANG_WARN_SUSPICIOUS_MOVE = YES;
				CLANG_WARN_UNGUARDED_AVAILABILITY = YES_AGGRESSIVE;
				CLANG_WARN_UNREACHABLE_CODE = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				COPY_PHASE_STRIP = NO;
				DEBUG_INFORMATION_FORMAT = "dwarf-with-dsym";
				ENABLE_NS_ASSERTIONS = NO;
				ENABLE_STRICT_OBJC_MSGSEND = YES;
				ENABLE_USER_SCRIPT_SANDBOXING = YES;
				GCC_C_LANGUAGE_STANDARD = gnu17;
				GCC_NO_COMMON_BLOCKS = YES;
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES_ERROR;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				IPHONEOS_DEPLOYMENT_TARGET = 18.1;
				LOCALIZATION_PREFERS_STRING_CATALOGS = YES;
				MTL_ENABLE_DEBUG_INFO = NO;
				MTL_FAST_MATH = YES;
				SDKROOT = iphoneos;
				SWIFT_COMPILATION_MODE = wholemodule;
				VALIDATE_PRODUCT = YES;
			};
			name = Release;
		};
		CB1C3FBD2D9D493D008FC7AB /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;
				ASSETCATALOG_COMPILER_GLOBAL_ACCENT_COLOR_NAME = AccentColor;
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 2;
				DEVELOPMENT_ASSET_PATHS = "\"MoveInsight/Preview Content\"";
				DEVELOPMENT_TEAM = 2VS9GH9QTB;
				ENABLE_PREVIEWS = YES;
				GENERATE_INFOPLIST_FILE = YES;
				INFOPLIST_FILE = MoveInsight/Info.plist;
				INFOPLIST_KEY_NSPhotoLibraryUsageDescription = "Needs permission to upload video";
				INFOPLIST_KEY_UIApplicationSceneManifest_Generation = YES;
				INFOPLIST_KEY_UIApplicationSupportsIndirectInputEvents = YES;
				INFOPLIST_KEY_UILaunchScreen_Generation = YES;
				INFOPLIST_KEY_UISupportedInterfaceOrientations_iPad = "UIInterfaceOrientationPortrait UIInterfaceOrientationPortraitUpsideDown UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight";
				INFOPLIST_KEY_UISupportedInterfaceOrientations_iPhone = "UIInterfaceOrientationPortrait UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight";
				IPHONEOS_DEPLOYMENT_TARGET = 17.0;
				LD_RUNPATH_SEARCH_PATHS = (
					"$(inherited)",
					"@executable_path/Frameworks",
				);
				MARKETING_VERSION = 1.0;
				PRODUCT_BUNDLE_IDENTIFIER = com.MoveInsight;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SUPPORTED_PLATFORMS = "iphoneos iphonesimulator";
				SUPPORTS_MACCATALYST = NO;
				SUPPORTS_MAC_DESIGNED_FOR_IPHONE_IPAD = NO;
				SUPPORTS_XR_DESIGNED_FOR_IPHONE_IPAD = NO;
				SWIFT_EMIT_LOC_STRINGS = YES;
				SWIFT_VERSION = 5.0;
				TARGETED_DEVICE_FAMILY = "1,2";
			};
			name = Debug;
		};
		CB1C3FBE2D9D493D008FC7AB /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;
				ASSETCATALOG_COMPILER_GLOBAL_ACCENT_COLOR_NAME = AccentColor;
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 2;
				DEVELOPMENT_ASSET_PATHS = "\"MoveInsight/Preview Content\"";
				DEVELOPMENT_TEAM = 2VS9GH9QTB;
				ENABLE_PREVIEWS = YES;
				GENERATE_INFOPLIST_FILE = YES;
				INFOPLIST_FILE = MoveInsight/Info.plist;
				INFOPLIST_KEY_NSPhotoLibraryUsageDescription = "Needs permission to upload video";
				INFOPLIST_KEY_UIApplicationSceneManifest_Generation = YES;
				INFOPLIST_KEY_UIApplicationSupportsIndirectInputEvents = YES;
				INFOPLIST_KEY_UILaunchScreen_Generation = YES;
				INFOPLIST_KEY_UISupportedInterfaceOrientations_iPad = "UIInterfaceOrientationPortrait UIInterfaceOrientationPortraitUpsideDown UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight";
				INFOPLIST_KEY_UISupportedInterfaceOrientations_iPhone = "UIInterfaceOrientationPortrait UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight";
				IPHONEOS_DEPLOYMENT_TARGET = 17.0;
				LD_RUNPATH_SEARCH_PATHS = (
					"$(inherited)",
					"@executable_path/Frameworks",
				);
				MARKETING_VERSION = 1.0;
				PRODUCT_BUNDLE_IDENTIFIER = com.MoveInsight;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SUPPORTED_PLATFORMS = "iphoneos iphonesimulator";
				SUPPORTS_MACCATALYST = NO;
				SUPPORTS_MAC_DESIGNED_FOR_IPHONE_IPAD = NO;
				SUPPORTS_XR_DESIGNED_FOR_IPHONE_IPAD = NO;
				SWIFT_EMIT_LOC_STRINGS = YES;
				SWIFT_VERSION = 5.0;
				TARGETED_DEVICE_FAMILY = "1,2";
			};
			name = Release;
		};
/* End XCBuildConfiguration section */

/* Begin XCConfigurationList section */
		CB1C3FA92D9D493B008FC7AB /* Build configuration list for PBXProject "MoveInsight" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				CB1C3FBA2D9D493D008FC7AB /* Debug */,
				CB1C3FBB2D9D493D008FC7AB /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		CB1C3FBC2D9D493D008FC7AB /* Build configuration list for PBXNativeTarget "MoveInsight" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				CB1C3FBD2D9D493D008FC7AB /* Debug */,
				CB1C3FBE2D9D493D008FC7AB /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
/* End XCConfigurationList section */
	};
	rootObject = CB1C3FA62D9D493B008FC7AB /* Project object */;
}
</file>

</files>
